{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4abea05a",
   "metadata": {},
   "source": [
    "### 0. CONFIGURACI√ìN INICIAL \n",
    "Importamos librerias, creamos rutas de las carpetas que se utilizaran, adicionalmente se verifica que exitan los archivos a trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6561c976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rutas configuradas correctamente ‚úÖ\n",
      "Archivo DIVIPOLA cargado correctamente ‚úÖ\n",
      "Filas: 1,122 | Columnas: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C√É¬≥digo Departamento</th>\n",
       "      <th>Nombre Departamento</th>\n",
       "      <th>C√É¬≥digo Municipio</th>\n",
       "      <th>Nombre Municipio</th>\n",
       "      <th>Tipo: Municipio / Isla / √É¬Årea no municipalizada</th>\n",
       "      <th>longitud</th>\n",
       "      <th>Latitud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>5001</td>\n",
       "      <td>MEDELL√É¬çN</td>\n",
       "      <td>Municipio</td>\n",
       "      <td>-75,581775</td>\n",
       "      <td>6,246631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>5002</td>\n",
       "      <td>ABEJORRAL</td>\n",
       "      <td>Municipio</td>\n",
       "      <td>-75,428739</td>\n",
       "      <td>5,789315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>5004</td>\n",
       "      <td>ABRIAQU√É¬ç</td>\n",
       "      <td>Municipio</td>\n",
       "      <td>-76,064304</td>\n",
       "      <td>6,632282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C√É¬≥digo Departamento Nombre Departamento  C√É¬≥digo Municipio  \\\n",
       "0                     5           ANTIOQUIA               5001   \n",
       "1                     5           ANTIOQUIA               5002   \n",
       "2                     5           ANTIOQUIA               5004   \n",
       "\n",
       "  Nombre Municipio Tipo: Municipio / Isla / √É¬Årea no municipalizada  \\\n",
       "0        MEDELL√É¬çN                                        Municipio   \n",
       "1        ABEJORRAL                                        Municipio   \n",
       "2        ABRIAQU√É¬ç                                        Municipio   \n",
       "\n",
       "     longitud   Latitud  \n",
       "0  -75,581775  6,246631  \n",
       "1  -75,428739  5,789315  \n",
       "2  -76,064304  6,632282  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de datos:\n",
      "C√É¬≥digo Departamento                                 int64\n",
      "Nombre Departamento                                 object\n",
      "C√É¬≥digo Municipio                                    int64\n",
      "Nombre Municipio                                    object\n",
      "Tipo: Municipio / Isla / √É¬Årea no municipalizada    object\n",
      "longitud                                            object\n",
      "Latitud                                             object\n",
      "dtype: object\n",
      "\n",
      "‚úÖ Departamentos √∫nicos y estandarizados:\n",
      "Filas: 33 | Columnas: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_DEPTO</th>\n",
       "      <th>DEPARTAMENTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08</td>\n",
       "      <td>ATL√ÅNTICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>BOGOT√Å, D.C.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  COD_DEPTO  DEPARTAMENTO\n",
       "0        05     ANTIOQUIA\n",
       "1        08     ATL√ÅNTICO\n",
       "2        11  BOGOT√Å, D.C."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de datos:\n",
      "COD_DEPTO       object\n",
      "DEPARTAMENTO    object\n",
      "dtype: object\n",
      "\n",
      "Archivo limpio guardado en: C:\\Estudios\\Talento_Tech\\Proyecto_Talento_Tech\\proyecto_movilidad_electrica\\datos\\limpios\\departamentos_limpios.csv\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Configuraciones generales de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# Definimos las rutas base de los datos  brutos y ya limpios\n",
    "ruta_datos = r\"C:\\Estudios\\Talento_Tech\\Proyecto_Talento_Tech\\proyecto_movilidad_electrica\\datos\\brutos\"\n",
    "ruta_salida = r\"C:\\Estudios\\Talento_Tech\\Proyecto_Talento_Tech\\proyecto_movilidad_electrica\\datos\\limpios\"\n",
    "\n",
    "\n",
    "# Verificamos que las rutas existan\n",
    "os.makedirs(ruta_salida, exist_ok=True)\n",
    "\n",
    "print(\"Rutas configuradas correctamente ‚úÖ\")\n",
    "\n",
    "def mostrar_resumen_df(df, n=3):\n",
    "    \"\"\"Resumen r√°pido de un DataFrame.\"\"\"\n",
    "    print(f\"Filas: {len(df):,} | Columnas: {len(df.columns)}\")\n",
    "    display(df.head(n))\n",
    "    print(\"\\nTipos de datos:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "def normalizar_texto(serie):\n",
    "    \"\"\"Estandariza textos (departamento/municipio).\"\"\"\n",
    "    return (serie.astype(str)\n",
    "                 .str.strip()\n",
    "                 .str.upper())\n",
    "\n",
    "def limpiar_anio(serie):\n",
    "    \"\"\"Convierte '2,022' ‚Üí 2022 (entero).\"\"\"\n",
    "    return (serie.astype(str)\n",
    "                 .str.replace(\",\", \"\", regex=False)\n",
    "                 .str.extract(r\"(\\d{4})\")[0]\n",
    "                 .astype(\"Int64\"))\n",
    "\n",
    "def a_numero_seguro(serie, quitar_miles=True, coma_decimal=False):\n",
    "    \"\"\"\n",
    "    Convierte strings a num√©rico manejando separadores (miles/decimal).\n",
    "    - quitar_miles=True elimina ',' y '.'\n",
    "    - coma_decimal=True trata ',' como decimal (convierte a '.')\n",
    "    \"\"\"\n",
    "    s = serie.astype(str).strip()\n",
    "    if coma_decimal:\n",
    "        s = s.replace(\".\", \"\", regex=False).replace(\",\", \".\", regex=False)\n",
    "    elif quitar_miles:\n",
    "        s = s.replace(\",\", \"\", regex=False).replace(\".\", \"\", regex=False)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "# ========================================\n",
    "\n",
    "# --- LIMPIEZA DE DEPARTAMENTOS (DIVIPOLA) USANDO POSICI√ìN DE COLUMNAS ---\n",
    "\n",
    "# 1Ô∏è‚É£ Cargar el archivo\n",
    "archivo_divipola = os.path.join(ruta_datos, \"DIVIPOLA-_C_digos_municipios.csv\")\n",
    "df_divipola = pd.read_csv(archivo_divipola, encoding=\"latin1\")\n",
    "\n",
    "print(\"Archivo DIVIPOLA cargado correctamente ‚úÖ\")\n",
    "mostrar_resumen_df(df_divipola)\n",
    "\n",
    "# 2Ô∏è‚É£ Tomamos las dos primeras columnas (por posici√≥n)\n",
    "df_departamentos = df_divipola.iloc[:, [0, 1]].copy()\n",
    "df_departamentos.columns = ['COD_DEPTO', 'DEPARTAMENTO']\n",
    "\n",
    "# 3Ô∏è‚É£ Corregimos problemas de tildes y e√±es\n",
    "def arreglar_tildes(texto):\n",
    "    \"\"\"Corrige textos mal codificados (acentos y e√±es).\"\"\"\n",
    "    if isinstance(texto, str):\n",
    "        texto = (texto\n",
    "                 .encode('latin1', errors='ignore')\n",
    "                 .decode('utf-8', errors='ignore')\n",
    "                 .strip()\n",
    "                 .upper())\n",
    "        # Reforzamos reemplazos comunes\n",
    "        reemplazos = {\n",
    "            \"ATLNTICO\": \"ATL√ÅNTICO\",\n",
    "            \"BOLVAR\": \"BOL√çVAR\",\n",
    "            \"BOYAC\": \"BOYAC√Å\",\n",
    "            \"QUINDO\": \"QUIND√çO\",\n",
    "            \"NARIO\": \"NARI√ëO\",\n",
    "            \"SAN ANDRS\": \"SAN ANDR√âS\",\n",
    "            \"VALLE DEL CAUCA\": \"VALLE DEL CAUCA\",\n",
    "        }\n",
    "        for k, v in reemplazos.items():\n",
    "            texto = texto.replace(k, v)\n",
    "        return texto\n",
    "    return texto\n",
    "\n",
    "df_departamentos['DEPARTAMENTO'] = df_departamentos['DEPARTAMENTO'].apply(arreglar_tildes)\n",
    "\n",
    "# 4Ô∏è‚É£ Aseguramos formato del c√≥digo (2 d√≠gitos)\n",
    "df_departamentos['COD_DEPTO'] = df_departamentos['COD_DEPTO'].astype(str).str.zfill(2)\n",
    "\n",
    "# 5Ô∏è‚É£ Eliminamos duplicados y ordenamos\n",
    "df_departamentos = (\n",
    "    df_departamentos.drop_duplicates()\n",
    "    .sort_values('COD_DEPTO')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 6Ô∏è‚É£ Mostramos resultado final\n",
    "print(\"\\n‚úÖ Departamentos √∫nicos y estandarizados:\")\n",
    "mostrar_resumen_df(df_departamentos)\n",
    "\n",
    "# 7Ô∏è‚É£ Guardamos el archivo limpio\n",
    "ruta_salida_departamentos = os.path.join(ruta_salida, \"departamentos_limpios.csv\")\n",
    "df_departamentos.to_csv(ruta_salida_departamentos, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"\\nArchivo limpio guardado en: {ruta_salida_departamentos}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade0ab7",
   "metadata": {},
   "source": [
    "\n",
    "### 1. CARGA Y LIMPIEZA DE VEHICULOS ELECTRICOS E HIBRIDOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca9ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo de veh√≠culos cargado (bruto).\n",
      "Filas: 56,545 | Columnas: 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMBUSTIBLE</th>\n",
       "      <th>ESTADO</th>\n",
       "      <th>MODELO</th>\n",
       "      <th>FECHA_REGISTRO</th>\n",
       "      <th>A√ëO_REGISTRO</th>\n",
       "      <th>CLASIFICACION</th>\n",
       "      <th>CLASE</th>\n",
       "      <th>SERVICIO</th>\n",
       "      <th>MARCA</th>\n",
       "      <th>LINEA</th>\n",
       "      <th>CARROCERIA</th>\n",
       "      <th>CILINDRAJE</th>\n",
       "      <th>MODALIDAD</th>\n",
       "      <th>ORGANISMO_TRANSITO</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>DEPARTAMENTO</th>\n",
       "      <th>CAPACIDAD_CARGA</th>\n",
       "      <th>CAPACIDAD_PASAJEROS</th>\n",
       "      <th>PESO</th>\n",
       "      <th>POTENCIA</th>\n",
       "      <th>EJES</th>\n",
       "      <th>CANTIDAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELECTRICO</td>\n",
       "      <td>ACTIVO</td>\n",
       "      <td>2,022</td>\n",
       "      <td>2022 Jun 30 12:00:00 AM</td>\n",
       "      <td>2,022</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>BUS</td>\n",
       "      <td>P√∫blico</td>\n",
       "      <td>BYD</td>\n",
       "      <td>BC11S01</td>\n",
       "      <td>CERRADA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PASAJEROS</td>\n",
       "      <td>SDM - BOGOTA D.C.</td>\n",
       "      <td>BOGOTA</td>\n",
       "      <td>Bogota D.C.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>20,000</td>\n",
       "      <td>402</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELECTRICO</td>\n",
       "      <td>ACTIVO</td>\n",
       "      <td>2,023</td>\n",
       "      <td>2022 Oct 21 12:00:00 AM</td>\n",
       "      <td>2,022</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>CAMIONETA</td>\n",
       "      <td>Particular</td>\n",
       "      <td>BYD</td>\n",
       "      <td>YUAN PRO EV</td>\n",
       "      <td>WAGON</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INSTITUTO DE MOVILIDAD DE PEREIRA</td>\n",
       "      <td>PEREIRA</td>\n",
       "      <td>Risaralda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,980</td>\n",
       "      <td>134</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELECTRICO</td>\n",
       "      <td>ACTIVO</td>\n",
       "      <td>2,014</td>\n",
       "      <td>2015 Sep 28 12:00:00 AM</td>\n",
       "      <td>2,015</td>\n",
       "      <td>MOTO</td>\n",
       "      <td>MOTOCICLETA</td>\n",
       "      <td>Particular</td>\n",
       "      <td>E-MOTORI</td>\n",
       "      <td>VITA</td>\n",
       "      <td>SIN CARROCERIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STRIA TTOyTTE MCPAL FLORENCIA</td>\n",
       "      <td>FLORENCIA</td>\n",
       "      <td>Caqueta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ELECTRICO</td>\n",
       "      <td>ACTIVO</td>\n",
       "      <td>2,021</td>\n",
       "      <td>2022 Aug 10 12:00:00 AM</td>\n",
       "      <td>2,022</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>CAMIONETA</td>\n",
       "      <td>P√∫blico</td>\n",
       "      <td>DONGFENG</td>\n",
       "      <td>DFA5030XXYABEV7</td>\n",
       "      <td>PANEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CARGA</td>\n",
       "      <td>STRIA TTOyTTE MCPAL FUNZA</td>\n",
       "      <td>FUNZA</td>\n",
       "      <td>Cundinamarca</td>\n",
       "      <td>845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,550</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELECTRICO</td>\n",
       "      <td>ACTIVO</td>\n",
       "      <td>2,022</td>\n",
       "      <td>2021 Oct 25 12:00:00 AM</td>\n",
       "      <td>2,021</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>CAMIONETA</td>\n",
       "      <td>Particular</td>\n",
       "      <td>BYD</td>\n",
       "      <td>SONG PRO EV</td>\n",
       "      <td>WAGON</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STRIA TTEyMOV CUND/EL ROSAL</td>\n",
       "      <td>EL ROSAL</td>\n",
       "      <td>Cundinamarca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,120</td>\n",
       "      <td>161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  COMBUSTIBLE  ESTADO MODELO           FECHA_REGISTRO A√ëO_REGISTRO  \\\n",
       "0   ELECTRICO  ACTIVO  2,022  2022 Jun 30 12:00:00 AM        2,022   \n",
       "1   ELECTRICO  ACTIVO  2,023  2022 Oct 21 12:00:00 AM        2,022   \n",
       "2   ELECTRICO  ACTIVO  2,014  2015 Sep 28 12:00:00 AM        2,015   \n",
       "3   ELECTRICO  ACTIVO  2,021  2022 Aug 10 12:00:00 AM        2,022   \n",
       "4   ELECTRICO  ACTIVO  2,022  2021 Oct 25 12:00:00 AM        2,021   \n",
       "\n",
       "  CLASIFICACION        CLASE    SERVICIO     MARCA            LINEA  \\\n",
       "0     AUTOMOVIL          BUS     P√∫blico       BYD          BC11S01   \n",
       "1     AUTOMOVIL    CAMIONETA  Particular       BYD      YUAN PRO EV   \n",
       "2          MOTO  MOTOCICLETA  Particular  E-MOTORI             VITA   \n",
       "3     AUTOMOVIL    CAMIONETA     P√∫blico  DONGFENG  DFA5030XXYABEV7   \n",
       "4     AUTOMOVIL    CAMIONETA  Particular       BYD      SONG PRO EV   \n",
       "\n",
       "       CARROCERIA  CILINDRAJE  MODALIDAD                 ORGANISMO_TRANSITO  \\\n",
       "0         CERRADA         NaN  PASAJEROS                  SDM - BOGOTA D.C.   \n",
       "1           WAGON         0.0        NaN  INSTITUTO DE MOVILIDAD DE PEREIRA   \n",
       "2  SIN CARROCERIA         0.0        NaN      STRIA TTOyTTE MCPAL FLORENCIA   \n",
       "3           PANEL         NaN      CARGA          STRIA TTOyTTE MCPAL FUNZA   \n",
       "4           WAGON         0.0        NaN        STRIA TTEyMOV CUND/EL ROSAL   \n",
       "\n",
       "   MUNICIPIO  DEPARTAMENTO CAPACIDAD_CARGA  CAPACIDAD_PASAJEROS    PESO  \\\n",
       "0     BOGOTA   Bogota D.C.             NaN                 49.0  20,000   \n",
       "1    PEREIRA     Risaralda             NaN                  NaN   1,980   \n",
       "2  FLORENCIA       Caqueta             NaN                  NaN     NaN   \n",
       "3      FUNZA  Cundinamarca             845                  NaN   2,550   \n",
       "4   EL ROSAL  Cundinamarca             NaN                  NaN   2,120   \n",
       "\n",
       "  POTENCIA  EJES  CANTIDAD  \n",
       "0      402   2.0         1  \n",
       "1      134   2.0         1  \n",
       "2      NaN   NaN         1  \n",
       "3       80   NaN         1  \n",
       "4      161   2.0         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de datos:\n",
      "COMBUSTIBLE            string[python]\n",
      "ESTADO                         object\n",
      "MODELO                         object\n",
      "FECHA_REGISTRO         string[python]\n",
      "A√ëO_REGISTRO           string[python]\n",
      "CLASIFICACION          string[python]\n",
      "CLASE                  string[python]\n",
      "SERVICIO               string[python]\n",
      "MARCA                  string[python]\n",
      "LINEA                          object\n",
      "CARROCERIA                     object\n",
      "CILINDRAJE                    float64\n",
      "MODALIDAD                      object\n",
      "ORGANISMO_TRANSITO             object\n",
      "MUNICIPIO              string[python]\n",
      "DEPARTAMENTO           string[python]\n",
      "CAPACIDAD_CARGA                object\n",
      "CAPACIDAD_PASAJEROS           float64\n",
      "PESO                           object\n",
      "POTENCIA                       object\n",
      "EJES                          float64\n",
      "CANTIDAD                        int64\n",
      "dtype: object\n",
      "\n",
      "‚ö†Ô∏è Departamentos no mapeados (revisar y, si aplica, actualizar referencia):\n",
      "- ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA\n",
      "\n",
      "=== Chequeos r√°pidos ===\n",
      "Rango de a√±os: 2010 -> 2022\n",
      "Departamentos √∫nicos: 28\n",
      "Municipios √∫nicos: 176\n",
      "Distribuci√≥n por tipo_vehiculo (%):\n",
      "tipo_vehiculo\n",
      "HEV    83.07\n",
      "EV     16.93\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "‚úÖ Vista previa del archivo limpio:\n",
      "Filas: 10 | Columnas: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo_vehiculo</th>\n",
       "      <th>combustible</th>\n",
       "      <th>anio_registro</th>\n",
       "      <th>fecha_registro</th>\n",
       "      <th>clasificacion</th>\n",
       "      <th>clase</th>\n",
       "      <th>servicio</th>\n",
       "      <th>marca</th>\n",
       "      <th>municipio</th>\n",
       "      <th>departamento</th>\n",
       "      <th>COD_DEPTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9369</th>\n",
       "      <td>EV</td>\n",
       "      <td>ELECTRICO</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022 May 31 12:00:00 AM</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>BUS</td>\n",
       "      <td>P√öBLICO</td>\n",
       "      <td>BYD</td>\n",
       "      <td>BOGOTA</td>\n",
       "      <td>BOGOT√Å, D.C.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11304</th>\n",
       "      <td>HEV</td>\n",
       "      <td>GASO ELEC</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022 Jun 03 12:00:00 AM</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>CAMIONETA</td>\n",
       "      <td>PARTICULAR</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>ENVIGADO</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41973</th>\n",
       "      <td>HEV</td>\n",
       "      <td>GASO ELEC</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021 Aug 27 12:00:00 AM</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>CAMIONETA</td>\n",
       "      <td>PARTICULAR</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>BUCARAMANGA</td>\n",
       "      <td>SANTANDER</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14245</th>\n",
       "      <td>HEV</td>\n",
       "      <td>GASO ELEC</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021 Nov 09 12:00:00 AM</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>CAMIONETA</td>\n",
       "      <td>PARTICULAR</td>\n",
       "      <td>FORD</td>\n",
       "      <td>BOGOTA</td>\n",
       "      <td>BOGOT√Å, D.C.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42595</th>\n",
       "      <td>HEV</td>\n",
       "      <td>GASO ELEC</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022 Mar 10 12:00:00 AM</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>PARTICULAR</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>VILLA DEL ROSARIO</td>\n",
       "      <td>NORTE DE SANTANDER</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37405</th>\n",
       "      <td>HEV</td>\n",
       "      <td>GASO ELEC</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022 Apr 05 12:00:00 AM</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>CAMIONETA</td>\n",
       "      <td>PARTICULAR</td>\n",
       "      <td>MAZDA</td>\n",
       "      <td>IBAGUE</td>\n",
       "      <td>TOLIMA</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23883</th>\n",
       "      <td>HEV</td>\n",
       "      <td>GASO ELEC</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021 Jul 02 12:00:00 AM</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>CAMPERO</td>\n",
       "      <td>PARTICULAR</td>\n",
       "      <td>SUBARU</td>\n",
       "      <td>BOGOTA</td>\n",
       "      <td>BOGOT√Å, D.C.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17000</th>\n",
       "      <td>HEV</td>\n",
       "      <td>GASO ELEC</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021 Jun 03 12:00:00 AM</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>CAMIONETA</td>\n",
       "      <td>PARTICULAR</td>\n",
       "      <td>KIA</td>\n",
       "      <td>BOGOTA</td>\n",
       "      <td>BOGOT√Å, D.C.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25556</th>\n",
       "      <td>HEV</td>\n",
       "      <td>GASO ELEC</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022 May 24 12:00:00 AM</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>CAMIONETA</td>\n",
       "      <td>PARTICULAR</td>\n",
       "      <td>MAZDA</td>\n",
       "      <td>CAJICA</td>\n",
       "      <td>CUNDINAMARCA</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48422</th>\n",
       "      <td>HEV</td>\n",
       "      <td>GASO ELEC</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022 Mar 22 12:00:00 AM</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>CAMPERO</td>\n",
       "      <td>PARTICULAR</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>SOACHA</td>\n",
       "      <td>CUNDINAMARCA</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tipo_vehiculo combustible  anio_registro           fecha_registro  \\\n",
       "9369             EV   ELECTRICO           2022  2022 May 31 12:00:00 AM   \n",
       "11304           HEV   GASO ELEC           2022  2022 Jun 03 12:00:00 AM   \n",
       "41973           HEV   GASO ELEC           2021  2021 Aug 27 12:00:00 AM   \n",
       "14245           HEV   GASO ELEC           2021  2021 Nov 09 12:00:00 AM   \n",
       "42595           HEV   GASO ELEC           2022  2022 Mar 10 12:00:00 AM   \n",
       "37405           HEV   GASO ELEC           2022  2022 Apr 05 12:00:00 AM   \n",
       "23883           HEV   GASO ELEC           2021  2021 Jul 02 12:00:00 AM   \n",
       "17000           HEV   GASO ELEC           2021  2021 Jun 03 12:00:00 AM   \n",
       "25556           HEV   GASO ELEC           2022  2022 May 24 12:00:00 AM   \n",
       "48422           HEV   GASO ELEC           2022  2022 Mar 22 12:00:00 AM   \n",
       "\n",
       "      clasificacion      clase    servicio   marca          municipio  \\\n",
       "9369      AUTOMOVIL        BUS     P√öBLICO     BYD             BOGOTA   \n",
       "11304     AUTOMOVIL  CAMIONETA  PARTICULAR  TOYOTA           ENVIGADO   \n",
       "41973     AUTOMOVIL  CAMIONETA  PARTICULAR  TOYOTA        BUCARAMANGA   \n",
       "14245     AUTOMOVIL  CAMIONETA  PARTICULAR    FORD             BOGOTA   \n",
       "42595     AUTOMOVIL  AUTOMOVIL  PARTICULAR  TOYOTA  VILLA DEL ROSARIO   \n",
       "37405     AUTOMOVIL  CAMIONETA  PARTICULAR   MAZDA             IBAGUE   \n",
       "23883     AUTOMOVIL    CAMPERO  PARTICULAR  SUBARU             BOGOTA   \n",
       "17000     AUTOMOVIL  CAMIONETA  PARTICULAR     KIA             BOGOTA   \n",
       "25556     AUTOMOVIL  CAMIONETA  PARTICULAR   MAZDA             CAJICA   \n",
       "48422     AUTOMOVIL    CAMPERO  PARTICULAR  TOYOTA             SOACHA   \n",
       "\n",
       "             departamento COD_DEPTO  \n",
       "9369         BOGOT√Å, D.C.        11  \n",
       "11304           ANTIOQUIA        05  \n",
       "41973           SANTANDER        68  \n",
       "14245        BOGOT√Å, D.C.        11  \n",
       "42595  NORTE DE SANTANDER        54  \n",
       "37405              TOLIMA        73  \n",
       "23883        BOGOT√Å, D.C.        11  \n",
       "17000        BOGOT√Å, D.C.        11  \n",
       "25556        CUNDINAMARCA        25  \n",
       "48422        CUNDINAMARCA        25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de datos:\n",
      "tipo_vehiculo             object\n",
      "combustible               object\n",
      "anio_registro              Int64\n",
      "fecha_registro    string[python]\n",
      "clasificacion             object\n",
      "clase                     object\n",
      "servicio                  object\n",
      "marca                     object\n",
      "municipio                 object\n",
      "departamento              object\n",
      "COD_DEPTO         string[python]\n",
      "dtype: object\n",
      "\n",
      "üíæ Archivo limpio guardado en: C:\\Estudios\\Talento_Tech\\Proyecto_Talento_Tech\\proyecto_movilidad_electrica\\datos\\limpios\\vehiculos_ev_hev_limpio.csv\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# INGESTA Y LIMPIEZA: VEH√çCULOS (EV/HEV)\n",
    "# ================================\n",
    "\n",
    "import os\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- 0) Helpers espec√≠ficos de este script ----------\n",
    "def clave_union_dep(serie: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Crea una clave robusta para unir departamentos:\n",
    "    - usa normalizar_texto (may√∫sculas, strip)\n",
    "    - quita diacr√≠ticos (tildes/√± -> n)\n",
    "    - elimina caracteres no alfab√©ticos (deja letras y espacios)\n",
    "    - colapsa espacios m√∫ltiples\n",
    "    \"\"\"\n",
    "    s = normalizar_texto(serie).fillna(\"\")\n",
    "    s = s.apply(lambda x: ''.join(ch for ch in unicodedata.normalize('NFKD', x)\n",
    "                                  if not unicodedata.combining(ch)))\n",
    "    s = s.str.replace(r\"[^A-Z\\s]\", \"\", regex=True)\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    return s\n",
    "\n",
    "# ---------- 1) Carga segura del archivo en bruto ----------\n",
    "ruta_ev = os.path.join(ruta_datos, \"Numero_de_Veh√≠culos_El√©ctricos_-_Hibridos_20251009.csv\")\n",
    "\n",
    "vehiculos_raw = pd.read_csv(\n",
    "    ruta_ev,\n",
    "    dtype={\n",
    "        \"A√ëO_REGISTRO\": \"string\",\n",
    "        \"FECHA_REGISTRO\": \"string\",\n",
    "        \"DEPARTAMENTO\": \"string\",\n",
    "        \"MUNICIPIO\": \"string\",\n",
    "        \"COMBUSTIBLE\": \"string\",\n",
    "        \"CLASIFICACION\": \"string\",\n",
    "        \"CLASE\": \"string\",\n",
    "        \"SERVICIO\": \"string\",\n",
    "        \"MARCA\": \"string\"\n",
    "    },\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Archivo de veh√≠culos cargado (bruto).\")\n",
    "mostrar_resumen_df(vehiculos_raw, n=5)\n",
    "\n",
    "# ---------- 2) Renombrado a nombres gen√©ricos y selecci√≥n ----------\n",
    "mapeo_columnas = {\n",
    "    \"COMBUSTIBLE\": \"combustible\",\n",
    "    \"FECHA_REGISTRO\": \"fecha_registro\",\n",
    "    \"A√ëO_REGISTRO\": \"anio_registro\",\n",
    "    \"CLASIFICACION\": \"clasificacion\",\n",
    "    \"CLASE\": \"clase\",\n",
    "    \"SERVICIO\": \"servicio\",\n",
    "    \"MARCA\": \"marca\",\n",
    "    \"MUNICIPIO\": \"municipio\",\n",
    "    \"DEPARTAMENTO\": \"departamento\"\n",
    "}\n",
    "\n",
    "vehiculos = vehiculos_raw.copy()\n",
    "# Si alguna columna no existe, se crea vac√≠a para no romper el flujo\n",
    "for col_ori in mapeo_columnas:\n",
    "    if col_ori not in vehiculos.columns:\n",
    "        vehiculos[col_ori] = pd.NA\n",
    "\n",
    "vehiculos = vehiculos[list(mapeo_columnas.keys())].rename(columns=mapeo_columnas)\n",
    "\n",
    "# ---------- 3) Limpieza de a√±o de registro ----------\n",
    "vehiculos[\"anio_registro\"] = limpiar_anio(vehiculos[\"anio_registro\"])\n",
    "\n",
    "# Si hay a√±os faltantes, intentamos extraer desde 'fecha_registro'\n",
    "if vehiculos[\"anio_registro\"].isna().any():\n",
    "    extra_anio = vehiculos[\"fecha_registro\"].astype(\"string\").str.extract(r\"(\\d{4})\")[0].astype(\"Int64\")\n",
    "    vehiculos[\"anio_registro\"] = vehiculos[\"anio_registro\"].fillna(extra_anio)\n",
    "\n",
    "# ---------- 4) Estandarizaci√≥n de texto en variables categ√≥ricas ----------\n",
    "cols_texto = [\"departamento\", \"municipio\", \"combustible\", \"clasificacion\", \"clase\", \"servicio\", \"marca\"]\n",
    "for c in cols_texto:\n",
    "    vehiculos[c] = normalizar_texto(vehiculos[c])\n",
    "\n",
    "# ================================\n",
    "# 4A) Armonizaci√≥n de DEPARTAMENTO con referencia DIVIPOLA\n",
    "# ================================\n",
    "ref_path = os.path.join(ruta_salida, \"departamentos_limpios.csv\")\n",
    "ref_deps = pd.read_csv(ref_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Claves de uni√≥n (mismo m√©todo en ambos lados)\n",
    "ref_deps[\"dep_join\"]  = clave_union_dep(ref_deps[\"DEPARTAMENTO\"])\n",
    "vehiculos[\"dep_join\"] = clave_union_dep(vehiculos[\"departamento\"])\n",
    "\n",
    "# === Alias de uni√≥n (APLICAR ANTES DEL MERGE) ===\n",
    "alias_map = {\n",
    "    # San Andr√©s (formas comunes en fuentes operativas)\n",
    "    \"SAN ANDRES\": \"ARCHIPIELAGO DE SAN ANDRES PROVIDENCIA Y SANTA CATALINA\",\n",
    "    \"SAN ANDRES ISLAS\": \"ARCHIPIELAGO DE SAN ANDRES PROVIDENCIA Y SANTA CATALINA\",\n",
    "    \"ARCHIPIELAGO DE SAN ANDRES\": \"ARCHIPIELAGO DE SAN ANDRES PROVIDENCIA Y SANTA CATALINA\",\n",
    "    # Boyac√° (variantes con prefijos)\n",
    "    \"DEPTO DE BOYACA\": \"BOYACA\",\n",
    "    \"DEPARTAMENTO DE BOYACA\": \"BOYACA\",\n",
    "    \"DPTO BOYACA\": \"BOYACA\"\n",
    "}\n",
    "vehiculos[\"dep_join\"] = vehiculos[\"dep_join\"].replace(alias_map)\n",
    "\n",
    "# (Opcional robusto) Duplicar filas alias en la referencia para cubrir m√°s casos\n",
    "alias_rows = pd.DataFrame({\n",
    "    \"dep_join\": [\n",
    "        \"SAN ANDRES\", \"SAN ANDRES ISLAS\", \"ARCHIPIELAGO DE SAN ANDRES\", \"BOYACA\"\n",
    "    ],\n",
    "    \"COD_DEPTO\": [\"88\",\"88\",\"88\",\"15\"],\n",
    "    \"DEPARTAMENTO\": [\n",
    "        \"ARCHIPI√âLAGO DE SAN ANDR√âS, PROVIDENCIA Y SANTA CATALINA\",\n",
    "        \"ARCHIPI√âLAGO DE SAN ANDR√âS, PROVIDENCIA Y SANTA CATALINA\",\n",
    "        \"ARCHIPI√âLAGO DE SAN ANDR√âS, PROVIDENCIA Y SANTA CATALINA\",\n",
    "        \"BOYAC√Å\"\n",
    "    ]\n",
    "})\n",
    "ref_deps = pd.concat([ref_deps, alias_rows], ignore_index=True)\n",
    "ref_deps = ref_deps.drop_duplicates(subset=[\"dep_join\"], keep=\"first\")\n",
    "\n",
    "# === MERGE (despu√©s de alias) ===\n",
    "vehiculos = vehiculos.merge(\n",
    "    ref_deps[[\"dep_join\", \"COD_DEPTO\", \"DEPARTAMENTO\"]],\n",
    "    on=\"dep_join\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_ref\")     # por si alguna vez coincidiera el nombre\n",
    ")\n",
    "\n",
    "# ---------- Diagn√≥stico de no mapeados (ANTES de formatear COD_DEPTO) ----------\n",
    "no_mapeados = vehiculos[vehiculos[\"COD_DEPTO\"].isna()][\"departamento\"].dropna().unique()\n",
    "if len(no_mapeados) > 0:\n",
    "    print(\"\\n‚ö†Ô∏è Departamentos no mapeados (revisar y, si aplica, actualizar referencia):\")\n",
    "    for d in no_mapeados:\n",
    "        print(\"-\", d)\n",
    "else:\n",
    "    print(\"\\n‚úÖ Todos los departamentos fueron armonizados con la referencia DIVIPOLA.\")\n",
    "\n",
    "# ---------- Formateo robusto de COD_DEPTO ----------\n",
    "# 1) convertir tolerante a num√©rico (cadenas/ruido -> NaN), preservando NaN reales\n",
    "vehiculos[\"COD_DEPTO\"] = pd.to_numeric(vehiculos[\"COD_DEPTO\"], errors=\"coerce\")\n",
    "# 2) ahora s√≠ a Int64 (permite NaN) y a 2 d√≠gitos\n",
    "vehiculos[\"COD_DEPTO\"] = (\n",
    "    vehiculos[\"COD_DEPTO\"]\n",
    "      .astype(\"Int64\")\n",
    "      .astype(\"string\")\n",
    "      .str.zfill(2)\n",
    ")\n",
    "\n",
    "# ---------- Tomar el nombre est√°ndar sin romper si cambia el sufijo ----------\n",
    "# En la mayor√≠a de casos la columna se llama exactamente \"DEPARTAMENTO\" (la tra√≠da del ref).\n",
    "# Si por alguna raz√≥n vino con sufijo, tomamos el que exista.\n",
    "col_std = None\n",
    "for cand in [\"DEPARTAMENTO\", \"DEPARTAMENTO_ref\", \"DEPARTAMENTO_std\"]:\n",
    "    if cand in vehiculos.columns:\n",
    "        col_std = cand\n",
    "        break\n",
    "\n",
    "if col_std is not None:\n",
    "    vehiculos[\"departamento\"] = vehiculos[col_std]\n",
    "# eliminar auxiliares sin romper si no existen\n",
    "vehiculos = vehiculos.drop(columns=[c for c in [\"DEPARTAMENTO\", \"DEPARTAMENTO_ref\", \"DEPARTAMENTO_std\", \"dep_join\"] if c in vehiculos.columns])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- 5) Clasificaci√≥n de TIPO_VEHICULO (EV / HEV / OTRO) ----------\n",
    "comb = vehiculos[\"combustible\"].fillna(\"\")\n",
    "\n",
    "es_hev = (\n",
    "    comb.str.contains(r\"\\bHIB\", regex=True) |\n",
    "    (comb.str.contains(r\"GAS\", regex=True) & comb.str.contains(r\"ELEC\", regex=True)) |\n",
    "    (comb.str.contains(r\"DIE\", regex=True) & comb.str.contains(r\"ELEC\", regex=True)) |\n",
    "    comb.str.contains(r\"\\bHEV\\b\", regex=True) |\n",
    "    comb.str.contains(r\"\\bPHEV\\b\", regex=True)\n",
    ")\n",
    "\n",
    "es_ev = comb.str.contains(r\"ELEC\", regex=True) & ~es_hev\n",
    "\n",
    "vehiculos[\"tipo_vehiculo\"] = np.where(es_hev, \"HEV\", np.where(es_ev, \"EV\", \"OTRO\"))\n",
    "\n",
    "# ---------- 6) Orden de columnas (sin romper si falta alguna) ----------\n",
    "orden_deseado = [\n",
    "    \"tipo_vehiculo\", \"combustible\", \"anio_registro\", \"fecha_registro\",\n",
    "    \"clasificacion\", \"clase\", \"servicio\", \"marca\", \"municipio\", \"departamento\", \"COD_DEPTO\"\n",
    "]\n",
    "orden_final = [c for c in orden_deseado if c in vehiculos.columns]\n",
    "vehiculos = vehiculos[orden_final]\n",
    "\n",
    "faltantes = [c for c in orden_deseado if c not in vehiculos.columns]\n",
    "if faltantes:\n",
    "    print(\"‚ÑπÔ∏è Columnas no presentes al reordenar (no se incluyen):\", faltantes)\n",
    "\n",
    "# ---------- 7) Chequeos r√°pidos ----------\n",
    "print(\"\\n=== Chequeos r√°pidos ===\")\n",
    "print(\"Rango de a√±os:\", vehiculos[\"anio_registro\"].min(), \"->\", vehiculos[\"anio_registro\"].max())\n",
    "print(\"Departamentos √∫nicos:\", vehiculos[\"departamento\"].nunique())\n",
    "print(\"Municipios √∫nicos:\", vehiculos[\"municipio\"].nunique())\n",
    "print(\"Distribuci√≥n por tipo_vehiculo (%):\")\n",
    "print((vehiculos[\"tipo_vehiculo\"].value_counts(dropna=False, normalize=True) * 100).round(2))\n",
    "\n",
    "# ---------- 8) Vista previa del archivo limpio ----------\n",
    "print(\"\\n‚úÖ Vista previa del archivo limpio:\")\n",
    "mostrar_resumen_df(vehiculos.sample(min(10, len(vehiculos))), n=10)\n",
    "\n",
    "# ---------- 9) Guardado del archivo limpio ----------\n",
    "nombre_salida = \"vehiculos_ev_hev_limpio.csv\"\n",
    "ruta_salida_archivo = os.path.join(ruta_salida, nombre_salida)\n",
    "vehiculos.to_csv(ruta_salida_archivo, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nüíæ Archivo limpio guardado en: {ruta_salida_archivo}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff614c",
   "metadata": {},
   "source": [
    "### 2. CARGA, LIMPIEZA y AJUSTE: PIB DEPARTAMENTAL\n",
    "Lee l√≠nea por l√≠nea, toma solo el primer segmento antes del ; (el resto son ‚Äúrellenos‚Äù).\n",
    "Limpia comillas escapadas y parsea con csv.reader (respeta comillas internas).\n",
    "Reconstruye el a√±o cuando viene como [\"2\",\"005\"].\n",
    "Filtra filas basura y normaliza anio y valor.\n",
    "Filtra ‚Äúconstantes‚Äù para quedarte solo con precios constantes 2015.\n",
    "Agrega por departamento y anio y deja la columna final como pib_const_2015_mil_mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2794cdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype final: Float64\n",
      "üíæ Guardado (machine): C:\\Estudios\\Talento_Tech\\Proyecto_Talento_Tech\\proyecto_movilidad_electrica\\datos\\limpios\\pib_departamental_const2015_limpio.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# PIB DEPARTAMENTAL (CONST. 2015) ‚Äì Limpieza, unificaci√≥n y export seguro\n",
    "# Salida: anio, codigo_depto, departamento, pib_const_2015_miles_mm\n",
    "# =========================================\n",
    "import os, re, csv, unicodedata\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ------- Rutas (ajusta a tu proyecto) ----\n",
    "ruta_pib = os.path.join(ruta_datos, \"PIB_Departamental_con_proyecci√≥n_20251014.csv\")\n",
    "out_base = os.path.join(ruta_salida, \"pib_departamental_const2015_limpio\")\n",
    "\n",
    "# ------- Cat√°logo can√≥nico DANE ----------\n",
    "CANON_DEPTOS = [\n",
    "    (\"05\",\"ANTIOQUIA\"), (\"08\",\"ATL√ÅNTICO\"), (\"11\",\"BOGOT√Å D.C.\"), (\"13\",\"BOL√çVAR\"),\n",
    "    (\"15\",\"BOYAC√Å\"), (\"17\",\"CALDAS\"), (\"18\",\"CAQUET√Å\"), (\"19\",\"CAUCA\"),\n",
    "    (\"20\",\"CESAR\"), (\"23\",\"C√ìRDOBA\"), (\"25\",\"CUNDINAMARCA\"), (\"27\",\"CHOC√ì\"),\n",
    "    (\"41\",\"HUILA\"), (\"44\",\"LA GUAJIRA\"), (\"47\",\"MAGDALENA\"), (\"50\",\"META\"),\n",
    "    (\"52\",\"NARI√ëO\"), (\"54\",\"NORTE DE SANTANDER\"), (\"63\",\"QUIND√çO\"), (\"66\",\"RISARALDA\"),\n",
    "    (\"68\",\"SANTANDER\"), (\"70\",\"SUCRE\"), (\"73\",\"TOLIMA\"), (\"76\",\"VALLE DEL CAUCA\"),\n",
    "    (\"81\",\"ARAUCA\"), (\"85\",\"CASANARE\"), (\"86\",\"PUTUMAYO\"),\n",
    "    (\"88\",\"SAN ANDR√âS, PROVIDENCIA Y SANTA CATALINA\"),\n",
    "    (\"91\",\"AMAZONAS\"), (\"94\",\"GUAIN√çA\"), (\"95\",\"GUAVIARE\"), (\"97\",\"VAUP√âS\"), (\"99\",\"VICHADA\")\n",
    "]\n",
    "CODE2NAME = {c:n for c,n in CANON_DEPTOS}\n",
    "VARIANTES_NOMBRE = {\n",
    "    \"ANTIOQUIA\": (\"05\",\"ANTIOQUIA\"),\n",
    "    \"ATLANTICO\": (\"08\",\"ATL√ÅNTICO\"),\n",
    "    \"BOGOTA D.C\": (\"11\",\"BOGOT√Å D.C.\"), \"BOGOTA DC\": (\"11\",\"BOGOT√Å D.C.\"), \"BOGOTA\": (\"11\",\"BOGOT√Å D.C.\"),\n",
    "    \"BOLIVAR\": (\"13\",\"BOL√çVAR\"), \"BOYACA\": (\"15\",\"BOYAC√Å\"), \"CALDAS\": (\"17\",\"CALDAS\"),\n",
    "    \"CAQUETA\": (\"18\",\"CAQUET√Å\"), \"CAUCA\": (\"19\",\"CAUCA\"), \"CESAR\": (\"20\",\"CESAR\"),\n",
    "    \"CORDOBA\": (\"23\",\"C√ìRDOBA\"), \"CUNDINAMARCA\": (\"25\",\"CUNDINAMARCA\"), \"CHOCO\": (\"27\",\"CHOC√ì\"),\n",
    "    \"HUILA\": (\"41\",\"HUILA\"), \"LA GUAJIRA\": (\"44\",\"LA GUAJIRA\"), \"MAGDALENA\": (\"47\",\"MAGDALENA\"),\n",
    "    \"META\": (\"50\",\"META\"), \"NARINO\": (\"52\",\"NARI√ëO\"), \"NORTE DE SANTANDER\": (\"54\",\"NORTE DE SANTANDER\"),\n",
    "    \"N. DE SANTANDER\": (\"54\",\"NORTE DE SANTANDER\"),\n",
    "    \"QUINDIO\": (\"63\",\"QUIND√çO\"), \"RISARALDA\": (\"66\",\"RISARALDA\"), \"SANTANDER\": (\"68\",\"SANTANDER\"),\n",
    "    \"SUCRE\": (\"70\",\"SUCRE\"), \"TOLIMA\": (\"73\",\"TOLIMA\"),\n",
    "    \"VALLE\": (\"76\",\"VALLE DEL CAUCA\"), \"VALLE DEL CAUCA\": (\"76\",\"VALLE DEL CAUCA\"),\n",
    "    \"ARAUCA\": (\"81\",\"ARAUCA\"), \"CASANARE\": (\"85\",\"CASANARE\"), \"PUTUMAYO\": (\"86\",\"PUTUMAYO\"),\n",
    "    \"SAN ANDRES\": (\"88\",\"SAN ANDR√âS, PROVIDENCIA Y SANTA CATALINA\"),\n",
    "    \"SAN ANDRES PROVIDENCIA Y SANTA CATALINA\": (\"88\",\"SAN ANDR√âS, PROVIDENCIA Y SANTA CATALINA\"),\n",
    "    \"ARCHIPIELAGO DE SAN ANDRES PROVIDENCIA Y SANTA CATALINA\": (\"88\",\"SAN ANDR√âS, PROVIDENCIA Y SANTA CATALINA\"),\n",
    "    \"AMAZONAS\": (\"91\",\"AMAZONAS\"), \"GUAINIA\": (\"94\",\"GUAIN√çA\"), \"GUAVIARE\": (\"95\",\"GUAVIARE\"),\n",
    "    \"VAUPES\": (\"97\",\"VAUP√âS\"), \"VICHADA\": (\"99\",\"VICHADA\"),\n",
    "}\n",
    "\n",
    "# ------- Utilidades de texto -------------\n",
    "def _normalize_text_value(s):\n",
    "    if pd.isna(s): return pd.NA\n",
    "    s = str(s).strip().upper()\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = s.replace(\"D.C.\", \"D.C\").replace(\"D C\", \"D.C\")\n",
    "    return s\n",
    "\n",
    "def normalize_text(x):\n",
    "    return x.map(_normalize_text_value) if isinstance(x, pd.Series) else _normalize_text_value(x)\n",
    "\n",
    "def canon_dep(cod, nombre):\n",
    "    cod2 = None\n",
    "    if cod:\n",
    "        m = re.search(r\"\\d+\", str(cod))\n",
    "        if m:\n",
    "            c = m.group(0).zfill(2)\n",
    "            if c in CODE2NAME:\n",
    "                return c, CODE2NAME[c]\n",
    "            cod2 = c\n",
    "    nom_norm = normalize_text(nombre) if nombre is not None else \"\"\n",
    "    if nom_norm in VARIANTES_NOMBRE:\n",
    "        return VARIANTES_NOMBRE[nom_norm]\n",
    "    return (cod2 if cod2 else \"\"), (nombre if nombre is not None else \"\")\n",
    "\n",
    "# ------- Lectura del CSV ‚Äúraro‚Äù ----------\n",
    "rows = []\n",
    "with open(ruta_pib, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "    for line in f:\n",
    "        inner = line.strip().split(\";\")[0]\n",
    "        if inner.startswith('\"') and inner.endswith('\"'): inner = inner[1:-1]\n",
    "        inner = inner.replace('\"\"', '\"')\n",
    "        parsed = next(csv.reader([inner], quotechar='\"', delimiter=',', skipinitialspace=True))\n",
    "        rows.append(parsed)\n",
    "\n",
    "def parse_rows_to_df(rows):\n",
    "    data = []\n",
    "    for r in rows:\n",
    "        if not r: continue\n",
    "        if any(h in r[0] for h in [\"A\\u00f1o\",\"A√ëO\",\"A√±o\",\"Tipo de precios\",\"Departamento\",\"Valor\"]):\n",
    "            continue\n",
    "        if len(r)==8 and r[0].isdigit() and r[1].isdigit():\n",
    "            r = [r[0]+r[1]] + r[2:8]\n",
    "        elif len(r)>=7:\n",
    "            r = r[:7]\n",
    "        else:\n",
    "            continue\n",
    "        data.append(r)\n",
    "    return pd.DataFrame(data, columns=[\"anio\",\"actividad\",\"sector\",\"tipo_precio\",\"codigo_depto\",\"departamento\",\"valor_miles_millones\"])\n",
    "\n",
    "pib = parse_rows_to_df(rows)\n",
    "\n",
    "# ------- Limpieza num√©rica ---------------\n",
    "def clean_num(s: str):\n",
    "    if pd.isna(s): return pd.NA\n",
    "    s = str(s).strip()\n",
    "    if s == \"\": return pd.NA\n",
    "    s = re.sub(r\"[^0-9,.\\-]\", \"\", s)\n",
    "    if \",\" in s and \".\" in s:\n",
    "        last = max(s.rfind(\",\"), s.rfind(\".\"))\n",
    "        int_part = re.sub(r\"[.,]\", \"\", s[:last])\n",
    "        frac_part = re.sub(r\"[.,]\", \"\", s[last+1:])\n",
    "        s = f\"{int_part}.{frac_part}\" if frac_part != \"\" else f\"{int_part}.0\"\n",
    "        try: return float(s)\n",
    "        except: return pd.NA\n",
    "    if \",\" in s and \".\" not in s:\n",
    "        if s.count(\",\")==1 and len(s.split(\",\")[-1]) in (1,2,3): s = s.replace(\",\", \".\")\n",
    "        else: s = s.replace(\",\", \"\")\n",
    "        try: return float(s)\n",
    "        except: return pd.NA\n",
    "    if \".\" in s and \",\" not in s:\n",
    "        if s.count(\".\")==1:\n",
    "            try: return float(s)\n",
    "            except: return pd.NA\n",
    "        last = s.rfind(\".\")\n",
    "        if len(s)-last-1 in (1,2,3):\n",
    "            s = f\"{s[:last].replace('.','')}.{s[last+1:]}\"\n",
    "        else:\n",
    "            s = s.replace(\".\", \"\")\n",
    "        try: return float(s)\n",
    "        except: return pd.NA\n",
    "    try: return float(s)\n",
    "    except: return pd.NA\n",
    "\n",
    "# ---- Tipos + unificaci√≥n de deptos ------\n",
    "pib[\"anio\"] = pd.to_numeric(pib[\"anio\"], errors=\"coerce\").astype(\"Int64\")\n",
    "pib[\"codigo_depto\"] = (pib[\"codigo_depto\"].astype(str).str.extract(r\"(\\d+)\", expand=False).fillna(\"\").str.zfill(2))\n",
    "\n",
    "canon = pib.apply(lambda r: canon_dep(r[\"codigo_depto\"], r[\"departamento\"]), axis=1, result_type=\"expand\")\n",
    "canon.columns = [\"codigo_depto_canon\",\"departamento_canon\"]\n",
    "pib[\"codigo_depto\"] = canon[\"codigo_depto_canon\"]\n",
    "pib[\"departamento\"] = canon[\"departamento_canon\"]\n",
    "\n",
    "pib[\"valor_miles_millones\"] = pd.to_numeric(pib[\"valor_miles_millones\"].map(clean_num), errors=\"coerce\")\n",
    "\n",
    "# ---- Filtro: constantes 2015 ------------\n",
    "mask = pib[\"tipo_precio\"].str.contains(\"constantes\", case=False, na=False) & pib[\"tipo_precio\"].str.contains(\"2015\", case=False, na=False)\n",
    "pib_c2015 = pib[mask].copy()\n",
    "\n",
    "# ---- Agregaci√≥n --------------------------\n",
    "pib_limpio = (pib_c2015\n",
    "    .groupby([\"anio\",\"codigo_depto\",\"departamento\"], as_index=False, dropna=False)[\"valor_miles_millones\"]\n",
    "    .sum(min_count=1)\n",
    "    .rename(columns={\"valor_miles_millones\":\"pib_const_2015_miles_mm\"})\n",
    "    .sort_values([\"anio\",\"departamento\"], kind=\"stable\")\n",
    ")\n",
    "\n",
    "# ---- Sanidad num√©rica FINAL (clave) -----\n",
    "def coerce_final_num(x):\n",
    "    \"\"\"Si a√∫n quedara texto, lo limpia a n√∫mero sin separadores de miles.\"\"\"\n",
    "    if pd.isna(x): return pd.NA\n",
    "    if isinstance(x, (int, float)): return float(x)\n",
    "    s = str(x)\n",
    "    s = s.replace(\"\\u00A0\",\"\").replace(\" \",\"\")\n",
    "    # quitar separadores de miles (cualquier . o , que NO sea el √∫ltimo separador decimal)\n",
    "    # regla: el √∫ltimo separador con 1‚Äì3 d√≠gitos a la derecha se considera decimal\n",
    "    if (\",\" in s) or (\".\" in s):\n",
    "        # normalizar: dejar solo el √∫ltimo como decimal\n",
    "        last = max(s.rfind(\",\"), s.rfind(\".\"))\n",
    "        intp = re.sub(r\"[.,]\", \"\", s[:last])\n",
    "        frac = re.sub(r\"[.,]\", \"\", s[last+1:])\n",
    "        s = f\"{intp}.{frac}\" if frac != \"\" else intp\n",
    "    s = re.sub(r\"[^0-9.\\-]\", \"\", s)\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "pib_limpio[\"pib_const_2015_miles_mm\"] = pib_limpio[\"pib_const_2015_miles_mm\"].map(coerce_final_num)\n",
    "pib_limpio[\"pib_const_2015_miles_mm\"] = pd.to_numeric(pib_limpio[\"pib_const_2015_miles_mm\"], errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "print(\"dtype final:\", pib_limpio[\"pib_const_2015_miles_mm\"].dtype)  # debe ser Float64\n",
    "\n",
    "# ---- Guardados: machine & excel ----------\n",
    "os.makedirs(os.path.dirname(out_base), exist_ok=True)\n",
    "\n",
    "# 1) CSV ‚Äúmachine-friendly‚Äù (coma, punto decimal)\n",
    "machine_csv = f\"{out_base}.csv\"\n",
    "pib_limpio.to_csv(machine_csv, index=False, encoding=\"utf-8-sig\", float_format=\"%.2f\")\n",
    "print(\"üíæ Guardado (machine):\", machine_csv)\n",
    "\n",
    "# 2) CSV ‚Äúexcel-friendly ES‚Äù (punto y coma; decimal coma)\n",
    "# excel_csv = f\"{out_base}_excel.csv\"\n",
    "# pib_limpio.to_csv(excel_csv, index=False, encoding=\"utf-8-sig\", sep=\";\", decimal=\",\", float_format=\"%.2f\")\n",
    "# print(\"üíæ Guardado (excel):  \", excel_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a464217f",
   "metadata": {},
   "source": [
    " ### 3. CARGA  Y LIMPIEZA DE POBLACI√ìN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca674222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Departamentos no mapeados (revisar referencia/entrada):\n",
      "- BOYAC√Å\n",
      "=== Resultado: poblaci√≥n por departamento (CNPV 2018, fila Total) ===\n",
      "Departamentos encontrados: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departamento</th>\n",
       "      <th>poblacion_2018</th>\n",
       "      <th>COD_DEPTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMAZONAS</td>\n",
       "      <td>66056</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>5974788</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARAUCA</td>\n",
       "      <td>239503</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARCHIPI√âLAGO DE SAN ANDR√âS, PROVIDENCIA Y SANT...</td>\n",
       "      <td>48299</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL√ÅNTICO</td>\n",
       "      <td>2342265</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOGOT√Å, D.C.</td>\n",
       "      <td>7181469</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOL√çVAR</td>\n",
       "      <td>1909460</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CALDAS</td>\n",
       "      <td>923472</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CAQUET√Å</td>\n",
       "      <td>359602</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CASANARE</td>\n",
       "      <td>379892</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        departamento  poblacion_2018 COD_DEPTO\n",
       "0                                           AMAZONAS           66056      91.0\n",
       "1                                          ANTIOQUIA         5974788       5.0\n",
       "2                                             ARAUCA          239503      81.0\n",
       "3  ARCHIPI√âLAGO DE SAN ANDR√âS, PROVIDENCIA Y SANT...           48299      88.0\n",
       "4                                          ATL√ÅNTICO         2342265       8.0\n",
       "5                                       BOGOT√Å, D.C.         7181469      11.0\n",
       "6                                            BOL√çVAR         1909460      13.0\n",
       "7                                             CALDAS          923472      17.0\n",
       "8                                            CAQUET√Å          359602      18.0\n",
       "9                                           CASANARE          379892      85.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Archivo limpio guardado en: C:\\Estudios\\Talento_Tech\\Proyecto_Talento_Tech\\proyecto_movilidad_electrica\\datos\\limpios\\personas_depto.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# CNPV 2018 ‚Äî Poblaci√≥n por departamento (fila \"TOTAL\")\n",
    "# Salida final: departamento (estandarizado), poblacion_2018, COD_DEPTO (string)\n",
    "# =========================================\n",
    "import os, csv, re\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "ruta_personas = os.path.join(ruta_datos, \"Personas.csv\")\n",
    "ref_deps_path = os.path.join(ruta_salida, \"departamentos_limpios.csv\")  # generado previamente\n",
    "\n",
    "# -------------------------------\n",
    "# Utilidades\n",
    "# -------------------------------\n",
    "def quitar_tildes(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', str(s))\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalizar_txt_col(serie: pd.Series) -> pd.Series:\n",
    "    # may√∫sculas, espacios colapsados\n",
    "    s = serie.astype(str).fillna(\"\").str.strip()\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.upper()\n",
    "    return s\n",
    "\n",
    "def clave_union_dep(serie: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Clave robusta para unir departamentos:\n",
    "    - may√∫sculas + trim + colapsar espacios\n",
    "    - quitar diacr√≠ticos\n",
    "    - dejar solo letras y espacios\n",
    "    \"\"\"\n",
    "    s = normalizar_txt_col(serie)\n",
    "    s = s.apply(lambda x: ''.join(ch for ch in unicodedata.normalize('NFKD', x)\n",
    "                                  if not unicodedata.combining(ch)))\n",
    "    s = s.str.replace(r\"[^A-Z\\s]\", \"\", regex=True)\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    return s\n",
    "\n",
    "# patr√≥n para \"A\": puede traer prefijo num√©rico + separador + nombre\n",
    "REG_DEP = r\"^(?:\\d{1,3}[-_\\s]+)?([A-Z√Å√â√ç√ì√ö√ú√ë ,\\.]+)$\"\n",
    "EXCLUIR_A = {\n",
    "    \"TOTAL NACIONAL\",\n",
    "    \"CABECERA\",\n",
    "    \"RURAL DISPERSO\",\n",
    "    \"CABECERA Y CENTROS POBLADOS Y RURAL DISPERSO\",\n",
    "    \"CENTROS POBLADOS Y RURAL DISPERSO\",\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Detectar separador y leer sin encabezado\n",
    "# -------------------------------\n",
    "with open(ruta_personas, \"r\", encoding=\"utf-8\", errors=\"replace\") as fh:\n",
    "    muestra = fh.read(8192)\n",
    "\n",
    "try:\n",
    "    dialect = csv.Sniffer().sniff(muestra, delimiters=[\",\",\";\",\"|\",\"\\t\"])\n",
    "    sep = dialect.delimiter\n",
    "except Exception:\n",
    "    sep = \";\"\n",
    "\n",
    "df = pd.read_csv(ruta_personas, sep=sep, header=None, dtype=\"string\", engine=\"python\")\n",
    "# asegurar A..E\n",
    "if df.shape[1] < 5:\n",
    "    df = df.reindex(columns=range(5))\n",
    "df = df.rename(columns={0:\"A\", 1:\"B\", 2:\"C\", 3:\"D\", 4:\"E\"})\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Normalizaci√≥n vectorizada\n",
    "# -------------------------------\n",
    "df[\"A_norm\"] = normalizar_txt_col(df[\"A\"])\n",
    "df[\"B_norm\"] = normalizar_txt_col(df[\"B\"])\n",
    "\n",
    "# D viene como \"5.974.788\" o \"44,164,417\"\n",
    "poblacion = (df[\"D\"].astype(str)\n",
    "               .str.replace(\" \", \"\", regex=False)\n",
    "               .str.replace(\".\", \"\", regex=False)\n",
    "               .str.replace(\",\", \"\", regex=False))\n",
    "df[\"D_num\"] = pd.to_numeric(poblacion, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3) Filtro de filas: \"TOTAL\" por departamento\n",
    "# -------------------------------\n",
    "mask_total = df[\"B_norm\"].eq(\"TOTAL\")\n",
    "mask_excluir = ~df[\"A_norm\"].isin(EXCLUIR_A) & ~df[\"A_norm\"].str.startswith(\"TOTAL NACIONAL\")\n",
    "mask_departamento = df[\"A_norm\"].str.match(REG_DEP)\n",
    "\n",
    "candidatas = df[mask_total & mask_excluir & mask_departamento].copy()\n",
    "\n",
    "# -------------------------------\n",
    "# 4) Extraer nombre de departamento (raw) y preparar clave de uni√≥n\n",
    "# -------------------------------\n",
    "# Tomamos el grupo 1 del patr√≥n (nombre) de forma vectorizada, manteniendo tildes aqu√≠;\n",
    "# la clave las quita para comparar contra referencia.\n",
    "candidatas[\"departamento_raw\"] = (\n",
    "    candidatas[\"A_norm\"]\n",
    "    .str.extract(REG_DEP, expand=False)\n",
    "    .str.strip(\" ,.\")\n",
    ")\n",
    "\n",
    "# Clave de uni√≥n sin tildes/diacr√≠ticos y sin punct\n",
    "candidatas[\"dep_join\"] = clave_union_dep(candidatas[\"departamento_raw\"])\n",
    "\n",
    "# -------------------------------\n",
    "# 4A) Cargar referencia DIVIPOLA y unir para estandarizar nombre + c√≥digo\n",
    "# -------------------------------\n",
    "ref_deps = pd.read_csv(ref_deps_path, encoding=\"utf-8-sig\")  # columnas: COD_DEPTO, DEPARTAMENTO\n",
    "ref_deps[\"dep_join\"] = clave_union_dep(ref_deps[\"DEPARTAMENTO\"])\n",
    "\n",
    "# Hacemos el merge\n",
    "candidatas = candidatas.merge(\n",
    "    ref_deps[[\"dep_join\", \"COD_DEPTO\", \"DEPARTAMENTO\"]],\n",
    "    on=\"dep_join\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Si hay no mapeados, avisa (debug)\n",
    "no_mapeados = candidatas[candidatas[\"COD_DEPTO\"].isna()][\"departamento_raw\"].dropna().unique()\n",
    "if len(no_mapeados) > 0:\n",
    "    print(\"\\n‚ö†Ô∏è Departamentos no mapeados (revisar referencia/entrada):\")\n",
    "    for d in no_mapeados:\n",
    "        print(\"-\", d)\n",
    "\n",
    "# Asegurar COD_DEPTO como string con ceros\n",
    "candidatas[\"COD_DEPTO\"] = candidatas[\"COD_DEPTO\"].astype(str).str.zfill(2)\n",
    "\n",
    "# -------------------------------\n",
    "# 5) Resultado final (estandarizado)\n",
    "# -------------------------------\n",
    "personas_depto = (\n",
    "    candidatas.loc[:, [\"DEPARTAMENTO\", \"D_num\", \"COD_DEPTO\"]]\n",
    "    .rename(columns={\"DEPARTAMENTO\": \"departamento\", \"D_num\": \"poblacion_2018\"})\n",
    "    .dropna(subset=[\"departamento\", \"poblacion_2018\"])\n",
    "    .drop_duplicates(subset=[\"departamento\"])   # por si hubiera repetidos\n",
    "    .sort_values(\"departamento\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"=== Resultado: poblaci√≥n por departamento (CNPV 2018, fila Total) ===\")\n",
    "print(\"Departamentos encontrados:\", personas_depto[\"departamento\"].nunique())\n",
    "display(personas_depto.head(10))\n",
    "\n",
    "# -------------------------------\n",
    "# 6) Guardar archivo limpio\n",
    "# -------------------------------\n",
    "nombre_salida = \"personas_depto.csv\"\n",
    "ruta_salida_archivo = os.path.join(ruta_salida, nombre_salida)\n",
    "\n",
    "# (garant√≠a extra) COD_DEPTO como texto 2 d√≠gitos\n",
    "personas_depto[\"COD_DEPTO\"] = personas_depto[\"COD_DEPTO\"].astype(str).str.zfill(2)\n",
    "\n",
    "personas_depto.to_csv(ruta_salida_archivo, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nüíæ Archivo limpio guardado en: {ruta_salida_archivo}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae3574e",
   "metadata": {},
   "source": [
    " ### 4. CARGA  Y LIMPIEZA DE AREAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ed04d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== √ÅREAS POR DPTO (km¬≤) ===\n",
      "Departamentos: 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo_depto</th>\n",
       "      <th>area_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05</td>\n",
       "      <td>62808.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08</td>\n",
       "      <td>3314.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1622.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>26720.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>23138.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>7425.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>92831.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>31242.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>22565.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>25086.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>22370.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27</td>\n",
       "      <td>48353.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   codigo_depto  area_km2\n",
       "0            05  62808.75\n",
       "1            08   3314.46\n",
       "2            11   1622.85\n",
       "3            13  26720.29\n",
       "4            15  23138.00\n",
       "5            17   7425.22\n",
       "6            18  92831.28\n",
       "7            19  31242.80\n",
       "8            20  22565.31\n",
       "9            23  25086.28\n",
       "10           25  22370.37\n",
       "11           27  48353.09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Archivo limpio guardado en: C:\\Estudios\\Talento_Tech\\Proyecto_Talento_Tech\\proyecto_movilidad_electrica\\datos\\limpios\\areas_departamentos.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# LIMPIEZA: √ÅREAS POR DEPARTAMENTO\n",
    "# Salida: codigo_depto, area_km2\n",
    "# =========================================\n",
    "import os, csv, re\n",
    "import pandas as pd\n",
    "\n",
    "ruta_area = os.path.join(ruta_datos, \"areas_departamentos.csv\")\n",
    "\n",
    "# -- 1) Detectar separador y cargar como texto --\n",
    "with open(ruta_area, \"r\", encoding=\"utf-8\", errors=\"replace\") as fh:\n",
    "    muestra = fh.read(8192)\n",
    "try:\n",
    "    dialect = csv.Sniffer().sniff(muestra, delimiters=[\",\",\";\",\"|\",\"\\t\"])\n",
    "    sep = dialect.delimiter\n",
    "except Exception:\n",
    "    sep = \",\"\n",
    "\n",
    "area_raw = pd.read_csv(ruta_area, sep=sep, dtype=\"string\", engine=\"python\")\n",
    "cols_orig = area_raw.columns\n",
    "\n",
    "# -- 2) Estandarizar nombres de columnas (lower, sin espacios) --\n",
    "norm = {c: re.sub(r\"\\s+\", \"_\", c.strip().lower()) for c in cols_orig}\n",
    "area_raw = area_raw.rename(columns=norm)\n",
    "\n",
    "# Candidatos para c√≥digo departamento y √°rea\n",
    "cands_cod = [c for c in area_raw.columns if re.search(r\"(cod|codi).*dep|^dep.*cod|^codigo_?depto|^cod_depto|^dpto(_|)cod|^codigo$\", c)]\n",
    "cands_area = [c for c in area_raw.columns if re.search(r\"area|km2|km_?2|superficie\", c)]\n",
    "\n",
    "if not cands_cod:\n",
    "    raise ValueError(\"No encontr√© columna de c√≥digo de departamento.\")\n",
    "if not cands_area:\n",
    "    raise ValueError(\"No encontr√© columna de √°rea.\")\n",
    "\n",
    "col_cod = cands_cod[0]\n",
    "col_area = cands_area[0]\n",
    "\n",
    "df = area_raw[[col_cod, col_area]].copy()\n",
    "\n",
    "# -- 3) C√≥digo a 2 d√≠gitos (extrae n√∫meros y zfill) --\n",
    "df[\"codigo_depto\"] = (\n",
    "    df[col_cod].astype(str)\n",
    "    .str.extract(r\"(\\d+)\", expand=False)  # toma solo d√≠gitos\n",
    "    .fillna(\"\")\n",
    "    .str.zfill(2)                         # 01..99\n",
    ")\n",
    "\n",
    "# -- 4) √Årea num√©rica: limpiar sin alterar valores correctos --\n",
    "s = df[col_area].astype(str).str.strip()\n",
    "\n",
    "def limpiar_area(v):\n",
    "    if pd.isna(v) or v.strip() == \"\":\n",
    "        return None\n",
    "    t = v.strip()\n",
    "\n",
    "    # eliminar caracteres no num√©ricos, coma o punto\n",
    "    t = re.sub(r\"[^0-9\\.,\\-]\", \"\", t)\n",
    "\n",
    "    # caso t√≠pico: valor ya bien con punto decimal -> mantenerlo\n",
    "    if re.match(r\"^\\d+\\.\\d+$\", t):\n",
    "        return t\n",
    "\n",
    "    # caso 1: usa coma como decimal (y sin punto)\n",
    "    if \",\" in t and \".\" not in t:\n",
    "        t = t.replace(\",\", \".\")\n",
    "        return t\n",
    "\n",
    "    # caso 2: tiene comas o puntos de miles (m√°s de un separador)\n",
    "    # eliminar todo menos el √∫ltimo punto o coma (decimal)\n",
    "    if t.count(\".\") > 1 or t.count(\",\") > 1 or (\",\" in t and \".\" in t):\n",
    "        # tomar el √∫ltimo separador como decimal\n",
    "        last_sep = max(t.rfind(\".\"), t.rfind(\",\"))\n",
    "        parte_entera = re.sub(r\"[.,]\", \"\", t[:last_sep])\n",
    "        parte_decimal = re.sub(r\"[.,]\", \"\", t[last_sep + 1:])\n",
    "        t = f\"{parte_entera}.{parte_decimal}\"\n",
    "        return t\n",
    "\n",
    "    # √∫ltimo recurso: quitar comas de miles\n",
    "    t = t.replace(\",\", \"\")\n",
    "    return t\n",
    "\n",
    "s_limpio = s.map(limpiar_area)\n",
    "df[\"area_km2\"] = pd.to_numeric(s_limpio, errors=\"coerce\")\n",
    "\n",
    "\n",
    "\n",
    "# -- 5) Limpieza final: quitar vac√≠os y consolidar duplicados si los hay --\n",
    "df = (\n",
    "    df.dropna(subset=[\"codigo_depto\", \"area_km2\"])\n",
    "      .query(\"codigo_depto != ''\")\n",
    "      .groupby(\"codigo_depto\", as_index=False)[\"area_km2\"].sum()  # por si viniera desagregado\n",
    "      .sort_values(\"codigo_depto\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# -- 6) Vista r√°pida --\n",
    "print(\"=== √ÅREAS POR DPTO (km¬≤) ===\")\n",
    "print(\"Departamentos:\", len(df))\n",
    "display(df.head(12))\n",
    "\n",
    "# -- 7) Guardar limpio (solo columnas solicitadas) --\n",
    "ruta_out = os.path.join(ruta_salida, \"areas_departamentos.csv\")\n",
    "df.to_csv(ruta_out, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"üíæ Archivo limpio guardado en: {ruta_out}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e050997",
   "metadata": {},
   "source": [
    "### 5. UNI√ìN DE ARCHIVOS DE POBLACI√ìN Y AREAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae17f938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEMOGRAF√çA DEPARTAMENTAL ===\n",
      "Columnas: ['codigo_depto', 'departamento', 'area_km2', 'poblacion_2018', 'densidad_hab_km2']\n",
      "Departamentos: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo_depto</th>\n",
       "      <th>departamento</th>\n",
       "      <th>area_km2</th>\n",
       "      <th>poblacion_2018</th>\n",
       "      <th>densidad_hab_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>62808.75</td>\n",
       "      <td>5974788</td>\n",
       "      <td>95.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08</td>\n",
       "      <td>ATL√ÅNTICO</td>\n",
       "      <td>3314.46</td>\n",
       "      <td>2342265</td>\n",
       "      <td>706.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>BOL√çVAR</td>\n",
       "      <td>26720.29</td>\n",
       "      <td>1909460</td>\n",
       "      <td>71.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>CALDAS</td>\n",
       "      <td>7425.22</td>\n",
       "      <td>923472</td>\n",
       "      <td>124.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>CAQUET√Å</td>\n",
       "      <td>92831.28</td>\n",
       "      <td>359602</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>CAUCA</td>\n",
       "      <td>31242.80</td>\n",
       "      <td>1243503</td>\n",
       "      <td>39.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>CESAR</td>\n",
       "      <td>22565.31</td>\n",
       "      <td>1098577</td>\n",
       "      <td>48.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>C√ìRDOBA</td>\n",
       "      <td>25086.28</td>\n",
       "      <td>1555596</td>\n",
       "      <td>62.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25</td>\n",
       "      <td>CUNDINAMARCA</td>\n",
       "      <td>22370.37</td>\n",
       "      <td>2792877</td>\n",
       "      <td>124.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27</td>\n",
       "      <td>CHOC√ì</td>\n",
       "      <td>48353.09</td>\n",
       "      <td>457412</td>\n",
       "      <td>9.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41</td>\n",
       "      <td>HUILA</td>\n",
       "      <td>18141.66</td>\n",
       "      <td>1009548</td>\n",
       "      <td>55.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>44</td>\n",
       "      <td>LA GUAJIRA</td>\n",
       "      <td>20618.62</td>\n",
       "      <td>825364</td>\n",
       "      <td>40.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   codigo_depto  departamento  area_km2  poblacion_2018  densidad_hab_km2\n",
       "0            05     ANTIOQUIA  62808.75         5974788             95.13\n",
       "1            08     ATL√ÅNTICO   3314.46         2342265            706.68\n",
       "2            13       BOL√çVAR  26720.29         1909460             71.46\n",
       "3            17        CALDAS   7425.22          923472            124.37\n",
       "4            18       CAQUET√Å  92831.28          359602              3.87\n",
       "5            19         CAUCA  31242.80         1243503              39.8\n",
       "6            20         CESAR  22565.31         1098577             48.68\n",
       "7            23       C√ìRDOBA  25086.28         1555596             62.01\n",
       "8            25  CUNDINAMARCA  22370.37         2792877            124.85\n",
       "9            27         CHOC√ì  48353.09          457412              9.46\n",
       "10           41         HUILA  18141.66         1009548             55.65\n",
       "11           44    LA GUAJIRA  20618.62          825364             40.03"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Archivo limpio guardado en: C:\\Estudios\\Talento_Tech\\Proyecto_Talento_Tech\\proyecto_movilidad_electrica\\datos\\limpios\\demografia_departamental.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# UNI√ìN POBLACI√ìN + √ÅREA -> DENSIDAD (hab/km¬≤)\n",
    "# Salida: codigo_depto, departamento, area_km2, poblacion_2018, densidad_hab_km2\n",
    "# =========================================\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def quitar_tildes(s):\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', str(s))\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def norm_nombre(s):\n",
    "    s = str(s).strip().upper()\n",
    "    s = quitar_tildes(s)\n",
    "    s = (s.replace(\".\", \"\").replace(\",\", \"\")\n",
    "           .replace(\"  \", \" \").replace(\"  \", \" \").strip())\n",
    "    return s\n",
    "\n",
    "# --- 1) Cargar insumos limpios ---\n",
    "ruta_personas_ok = os.path.join(ruta_salida, \"personas_depto.csv\")          # departamento, poblacion_2018\n",
    "ruta_areas_ok    = os.path.join(ruta_salida, \"areas_departamentos.csv\")     # codigo_depto, area_km2\n",
    "personas = pd.read_csv(ruta_personas_ok, dtype={\"departamento\":\"string\"})\n",
    "areas    = pd.read_csv(ruta_areas_ok,    dtype={\"codigo_depto\":\"string\"})\n",
    "\n",
    "# --- 2) Construir puente c√≥digo<->nombre ---\n",
    "ruta_pib_ok = os.path.join(ruta_salida, \"pib_departamental_const2015_limpio.csv\")\n",
    "if os.path.exists(ruta_pib_ok):\n",
    "    tmp = pd.read_csv(ruta_pib_ok, dtype={\"codigo_depto\":\"string\"})\n",
    "    divi = tmp[[\"codigo_depto\", \"departamento\"]].dropna().drop_duplicates().copy()\n",
    "else:\n",
    "    divi = pd.DataFrame({\n",
    "        \"codigo_depto\": [\"05\",\"08\",\"11\",\"13\",\"15\",\"17\",\"18\",\"19\",\"20\",\"23\",\"25\",\"27\",\"41\",\"44\",\"47\",\n",
    "                         \"50\",\"52\",\"54\",\"63\",\"66\",\"68\",\"70\",\"73\",\"76\",\"81\",\"85\",\"86\",\"88\",\"91\",\"94\",\"95\",\"97\",\"99\"],\n",
    "        \"departamento\": [\"ANTIOQUIA\",\"ATLANTICO\",\"BOGOTA D C\",\"BOLIVAR\",\"BOYACA\",\"CALDAS\",\"CAQUETA\",\"CAUCA\",\n",
    "                         \"CESAR\",\"CORDOBA\",\"CUNDINAMARCA\",\"CHOCO\",\"HUILA\",\"LA GUAJIRA\",\"MAGDALENA\",\"META\",\"NARINO\",\n",
    "                         \"NORTE DE SANTANDER\",\"QUINDIO\",\"RISARALDA\",\"SANTANDER\",\"SUCRE\",\"TOLIMA\",\"VALLE DEL CAUCA\",\n",
    "                         \"ARAUCA\",\"CASANARE\",\"PUTUMAYO\",\"SAN ANDRES PROVIDENCIA Y SANTA CATALINA\",\"AMAZONAS\",\n",
    "                         \"GUAINIA\",\"GUAVIARE\",\"VAUPES\",\"VICHADA\"]\n",
    "    })\n",
    "\n",
    "# normalizaciones para unir\n",
    "divi[\"dep_norm\"]     = divi[\"departamento\"].map(norm_nombre)\n",
    "personas[\"dep_norm\"] = personas[\"departamento\"].map(norm_nombre)\n",
    "aliases = {\n",
    "    \"BOGOTA DC\": \"BOGOTA D C\",\n",
    "    \"BOGOTA D C\": \"BOGOTA D C\",\n",
    "    \"ARCHIPIELAGO DE SAN ANDRES PROVIDENCIA Y SANTA CATALINA\": \n",
    "        \"SAN ANDRES PROVIDENCIA Y SANTA CATALINA\"\n",
    "}\n",
    "personas[\"dep_norm\"] = personas[\"dep_norm\"].replace(aliases)\n",
    "\n",
    "# --- 3) Unir personas + divi, quedarnos con una sola columna 'departamento' ---\n",
    "poblacion_cod = personas.merge(\n",
    "    divi[[\"codigo_depto\",\"dep_norm\",\"departamento\"]]\n",
    "           .rename(columns={\"departamento\":\"departamento_divi\"}),\n",
    "    on=\"dep_norm\", how=\"left\"\n",
    ")\n",
    "\n",
    "# si el puente no trae nombre, usar el de personas\n",
    "poblacion_cod[\"departamento_personas\"] = personas[\"departamento\"].map(norm_nombre)\n",
    "poblacion_cod[\"departamento\"] = poblacion_cod[\"departamento_divi\"].fillna(poblacion_cod[\"departamento_personas\"])\n",
    "\n",
    "# aseguramos tipos\n",
    "poblacion_cod[\"codigo_depto\"] = poblacion_cod[\"codigo_depto\"].astype(\"string\")\n",
    "poblacion_cod[\"poblacion_2018\"] = pd.to_numeric(poblacion_cod[\"poblacion_2018\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# --- 4) Unir con √°reas (por c√≥digo) ---\n",
    "demografia = poblacion_cod.merge(areas, on=\"codigo_depto\", how=\"left\")\n",
    "\n",
    "# --- 4A) S√ìLO ESTANDARIZAR NOMBRE DEPARTAMENTO SEG√öN REFERENCIA (sin tocar nada m√°s) ---\n",
    "ruta_ref_deps = os.path.join(ruta_salida, \"departamentos_limpios.csv\")  # columnas: COD_DEPTO, DEPARTAMENTO\n",
    "ref_deps = pd.read_csv(ruta_ref_deps, encoding=\"utf-8-sig\", dtype={\"COD_DEPTO\":\"string\"})\n",
    "# asegurar 2 d√≠gitos en el c√≥digo de referencia y en el dataset actual\n",
    "ref_deps[\"COD_DEPTO\"] = ref_deps[\"COD_DEPTO\"].astype(str).str.zfill(2)\n",
    "demografia[\"codigo_depto\"] = demografia[\"codigo_depto\"].astype(str).str.zfill(2)\n",
    "\n",
    "demografia = demografia.merge(\n",
    "    ref_deps[[\"COD_DEPTO\", \"DEPARTAMENTO\"]].rename(columns={\"COD_DEPTO\":\"codigo_depto\"}),\n",
    "    on=\"codigo_depto\", how=\"left\"\n",
    ")\n",
    "\n",
    "# reemplazamos el nombre con el oficial (tildes correctas)\n",
    "# si por alguna raz√≥n no se encuentra, conservamos el que ya ten√≠amos\n",
    "demografia[\"departamento\"] = demografia[\"DEPARTAMENTO\"].fillna(demografia[\"departamento\"])\n",
    "demografia = demografia.drop(columns=[\"DEPARTAMENTO\"])\n",
    "\n",
    "# --- 5) Calcular densidad y seleccionar columnas finales ---\n",
    "demografia[\"area_km2\"] = pd.to_numeric(demografia[\"area_km2\"], errors=\"coerce\")\n",
    "demografia[\"densidad_hab_km2\"] = demografia[\"poblacion_2018\"] / demografia[\"area_km2\"]\n",
    "\n",
    "cols_finales = [\"codigo_depto\",\"departamento\",\"area_km2\",\"poblacion_2018\",\"densidad_hab_km2\"]\n",
    "# si alguna no existe por nombre, ajustamos de forma segura\n",
    "colmap = {c: (c if c in demografia.columns else None) for c in cols_finales}\n",
    "# construir dataframe final tomando las columnas presentes\n",
    "demografia_final = demografia[[c for c in cols_finales if c in demografia.columns]].copy()\n",
    "\n",
    "# ordenar y limpiar\n",
    "demografia_final = (demografia_final\n",
    "                    .sort_values(\"codigo_depto\")\n",
    "                    .reset_index(drop=True))\n",
    "\n",
    "print(\"=== DEMOGRAF√çA DEPARTAMENTAL ===\")\n",
    "print(\"Columnas:\", list(demografia_final.columns))\n",
    "print(\"Departamentos:\", demografia_final.shape[0])\n",
    "display(demografia_final.head(12))\n",
    "\n",
    "# --- 6) Guardar ---\n",
    "ruta_out = os.path.join(ruta_salida, \"demografia_departamental.csv\")\n",
    "demografia_final.to_csv(ruta_out, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"üíæ Archivo limpio guardado en: {ruta_out}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de01b4c",
   "metadata": {},
   "source": [
    "### 6. UBICACI√ìN ESTACIONES EPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65686077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Estaciones EPM (Antioquia) ‚Äî LIMPIEZA LISTA\n",
      "Filas finales: 55\n",
      "Guardado en: C:\\Estudios\\Talento_Tech\\Proyecto_Talento_Tech\\proyecto_movilidad_electrica\\datos\\limpios\\estaciones_epm_antioquia.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo_estacion</th>\n",
       "      <th>estacion</th>\n",
       "      <th>ciudad</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estaci√≥n de carga el√©ctrica EPM</td>\n",
       "      <td>Aeropuerto</td>\n",
       "      <td>Rionegro</td>\n",
       "      <td>6.18</td>\n",
       "      <td>-75.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Estaci√≥n de carga el√©ctrica EPM</td>\n",
       "      <td>√âxito Poblado</td>\n",
       "      <td>Medell√≠n</td>\n",
       "      <td>6.21</td>\n",
       "      <td>-75.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Estaci√≥n de carga el√©ctrica EPM</td>\n",
       "      <td>√âxito Poblado</td>\n",
       "      <td>Medell√≠n</td>\n",
       "      <td>6.21</td>\n",
       "      <td>-75.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estaci√≥n de carga el√©ctrica EPM</td>\n",
       "      <td>Exposiciones</td>\n",
       "      <td>Medell√≠n</td>\n",
       "      <td>6.24</td>\n",
       "      <td>-75.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estaci√≥n de carga el√©ctrica EPM</td>\n",
       "      <td>EDS Texaco Vegas</td>\n",
       "      <td>Envigado</td>\n",
       "      <td>6.18</td>\n",
       "      <td>-75.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Estaci√≥n de carga el√©ctrica EPM</td>\n",
       "      <td>1er Parque Laureles</td>\n",
       "      <td>Medell√≠n</td>\n",
       "      <td>6.25</td>\n",
       "      <td>-75.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Estaci√≥n de carga el√©ctrica EPM</td>\n",
       "      <td>1er Parque Laureles</td>\n",
       "      <td>Medell√≠n</td>\n",
       "      <td>6.25</td>\n",
       "      <td>-75.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Estaci√≥n de carga el√©ctrica EPM</td>\n",
       "      <td>CC Los Molinos</td>\n",
       "      <td>Medell√≠n</td>\n",
       "      <td>6.23</td>\n",
       "      <td>-75.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Estaci√≥n de carga el√©ctrica EPM</td>\n",
       "      <td>CC Los Molinos</td>\n",
       "      <td>Medell√≠n</td>\n",
       "      <td>6.23</td>\n",
       "      <td>-75.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Estaci√≥n de carga el√©ctrica EPM</td>\n",
       "      <td>CC Mayorca</td>\n",
       "      <td>Sabaneta</td>\n",
       "      <td>6.16</td>\n",
       "      <td>-75.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tipo_estacion             estacion    ciudad  latitud  \\\n",
       "0  Estaci√≥n de carga el√©ctrica EPM           Aeropuerto  Rionegro     6.18   \n",
       "1  Estaci√≥n de carga el√©ctrica EPM        √âxito Poblado  Medell√≠n     6.21   \n",
       "2  Estaci√≥n de carga el√©ctrica EPM        √âxito Poblado  Medell√≠n     6.21   \n",
       "3  Estaci√≥n de carga el√©ctrica EPM         Exposiciones  Medell√≠n     6.24   \n",
       "4  Estaci√≥n de carga el√©ctrica EPM     EDS Texaco Vegas  Envigado     6.18   \n",
       "5  Estaci√≥n de carga el√©ctrica EPM  1er Parque Laureles  Medell√≠n     6.25   \n",
       "6  Estaci√≥n de carga el√©ctrica EPM  1er Parque Laureles  Medell√≠n     6.25   \n",
       "7  Estaci√≥n de carga el√©ctrica EPM       CC Los Molinos  Medell√≠n     6.23   \n",
       "8  Estaci√≥n de carga el√©ctrica EPM       CC Los Molinos  Medell√≠n     6.23   \n",
       "9  Estaci√≥n de carga el√©ctrica EPM           CC Mayorca  Sabaneta     6.16   \n",
       "\n",
       "   longitud  \n",
       "0    -75.44  \n",
       "1    -75.57  \n",
       "2    -75.57  \n",
       "3    -75.58  \n",
       "4    -75.59  \n",
       "5    -75.59  \n",
       "6    -75.59  \n",
       "7    -75.60  \n",
       "8    -75.60  \n",
       "9    -75.60  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================\n",
    "# 6) LIMPIEZA SIMPLE: ESTACIONES EPM (ANTIOQUIA)\n",
    "# Solo dejamos: tipo_estacion, estacion, ciudad, latitud, longitud\n",
    "# =========================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------- Config ----------\n",
    "archivo_entrada = \"Estaciones_de_Gas_Natural_Vehicular_y_Carga_El√©ctrica_‚Äì_EPM_20250926.csv\"  # AJUSTA si tu archivo se llama diferente\n",
    "ruta_in = os.path.join(ruta_datos, archivo_entrada)\n",
    "ruta_out = os.path.join(ruta_salida, \"estaciones_epm_antioquia.csv\")\n",
    "\n",
    "# ---------- Lectura con encodings comunes ----------\n",
    "ultimo_error = None\n",
    "for enc in [\"utf-8-sig\", \"utf-8\", \"latin-1\", \"cp1252\"]:\n",
    "    try:\n",
    "        estaciones = pd.read_csv(ruta_in, encoding=enc)\n",
    "        break\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"No se encontr√≥ el archivo: {ruta_in}\")\n",
    "    except Exception as e:\n",
    "        ultimo_error = e\n",
    "else:\n",
    "    raise RuntimeError(f\"No pude leer el archivo {ruta_in}. √öltimo error: {ultimo_error}\")\n",
    "\n",
    "# ---------- Arreglo b√°sico de mojibake en NOMBRES de columnas ----------\n",
    "def fix_mojibake_colname(s: str) -> str:\n",
    "    rep = {\n",
    "        \"√É¬°\": \"√°\", \"√É¬©\": \"√©\", \"√É√≠\": \"√≠\", \"√É¬≠\": \"√≠\", \"√É¬≥\": \"√≥\", \"√É¬∫\": \"√∫\",\n",
    "        \"√É¬±\": \"√±\", \"√É‚Äò\": \"√ë\", \"√É‚Äú\": \"√ì\", \"√É‚Ä∞\": \"√â\", \"√É\": \"√ç\"  # fallback com√∫n\n",
    "    }\n",
    "    for k,v in rep.items():\n",
    "        s = s.replace(k, v)\n",
    "    return s\n",
    "\n",
    "estaciones.columns = [fix_mojibake_colname(c) for c in estaciones.columns]\n",
    "\n",
    "# Normalizamos a min√∫sculas sin espacios extra\n",
    "cols_map = {c: c.strip().lower() for c in estaciones.columns}\n",
    "estaciones.rename(columns=cols_map, inplace=True)\n",
    "\n",
    "# ---------- Detecci√≥n de columnas de inter√©s ----------\n",
    "# Aliases que cubren tus nombres exactos y variantes habituales\n",
    "ALIAS_TIPO     = {\"tipo de estacion\", \"tipo de estaci√≥n\", \"tipo_estacion\", \"tipo_estaci√≥n\", \"tipo\"}\n",
    "ALIAS_NOMBRE   = {\"estacion\", \"estaci√≥n\"}\n",
    "ALIAS_CIUDAD   = {\"ciudad\", \"municipio\"}\n",
    "ALIAS_LAT      = {\"latitud\", \"latitude\", \"lat\"}\n",
    "ALIAS_LON      = {\"longitud\", \"longitude\", \"lon\"}\n",
    "\n",
    "def pick(df_cols, alias_set):\n",
    "    for a in alias_set:\n",
    "        if a in df_cols:\n",
    "            return a\n",
    "    return None\n",
    "\n",
    "df_cols = set(estaciones.columns)\n",
    "\n",
    "c_tipo = pick(df_cols, ALIAS_TIPO)\n",
    "c_nom  = pick(df_cols, ALIAS_NOMBRE)\n",
    "c_ciu  = pick(df_cols, ALIAS_CIUDAD)\n",
    "c_lat  = pick(df_cols, ALIAS_LAT)\n",
    "c_lon  = pick(df_cols, ALIAS_LON)\n",
    "\n",
    "faltantes = [n for n,(c) in {\n",
    "    \"tipo_estacion\": c_tipo, \"estacion\": c_nom,\n",
    "    \"ciudad\": c_ciu, \"latitud\": c_lat, \"longitud\": c_lon\n",
    "}.items() if c is None]\n",
    "\n",
    "if faltantes:\n",
    "    raise KeyError(\n",
    "        \"No encontr√© estas columnas requeridas en el CSV: \"\n",
    "        + \", \".join(faltantes)\n",
    "        + f\"\\nColumnas disponibles: {sorted(estaciones.columns)}\"\n",
    "    )\n",
    "\n",
    "# ---------- Subset + renombre est√°ndar ----------\n",
    "df = estaciones[[c_tipo, c_nom, c_ciu, c_lat, c_lon]].copy()\n",
    "df.columns = [\"tipo_estacion\", \"estacion\", \"ciudad\", \"latitud\", \"longitud\"]\n",
    "\n",
    "# ---------- Limpieza m√≠nima ----------\n",
    "# Strip textos\n",
    "for c in [\"tipo_estacion\", \"estacion\", \"ciudad\"]:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# Lat/Lon a float (corrige coma decimal)\n",
    "def to_float(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    s = str(s).strip().replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df[\"latitud\"] = df[\"latitud\"].map(to_float)\n",
    "df[\"longitud\"] = df[\"longitud\"].map(to_float)\n",
    "\n",
    "# Quitar filas sin coordenadas v√°lidas\n",
    "df = df.dropna(subset=[\"latitud\", \"longitud\"]).reset_index(drop=True)\n",
    "\n",
    "# ---------- Guardado ----------\n",
    "os.makedirs(ruta_salida, exist_ok=True)\n",
    "df.to_csv(ruta_out, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Estaciones EPM (Antioquia) ‚Äî LIMPIEZA LISTA\")\n",
    "print(f\"Filas finales: {len(df)}\")\n",
    "print(f\"Guardado en: {ruta_out}\")\n",
    "\n",
    "display(df.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5536dbc7",
   "metadata": {},
   "source": [
    "### Dataset maestro de vehiculos y pib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6648b447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Guardado: C:\\Estudios\\Talento_Tech\\Proyecto_Talento_Tech\\proyecto_movilidad_electrica\\datos\\limpios\\vehiculos_pib.csv\n",
      "Shape: (212, 6)\n",
      "Columnas: ['anio', 'codigo_departamento', 'departamento', 'ev_registrados', 'hev_registrados', 'pib_const_2015']\n",
      "NaNs por columna:\n",
      " anio                   0\n",
      "codigo_departamento    0\n",
      "departamento           0\n",
      "ev_registrados         0\n",
      "hev_registrados        0\n",
      "pib_const_2015         0\n",
      "dtype: int64\n",
      "Duplicados (departamento, anio): 0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Dataset 2: Veh√≠culos registrados (EV / HEV) + PIB\n",
    "Columnas finales:\n",
    "anio, codigo_departamento, departamento, ev_registrados, hev_registrados, pib_const_2015\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# 1) Rutas\n",
    "# =========================\n",
    "BASE = Path(r\"C:\\Estudios\\Talento_Tech\\Proyecto_Talento_Tech\\proyecto_movilidad_electrica\\datos\\limpios\")\n",
    "\n",
    "VEH_PATH = BASE / \"vehiculos_ev_hev_limpio.csv\"\n",
    "PIB_PATH = BASE / \"pib_departamental_const2015_limpio.csv\"\n",
    "OUT_PATH = BASE / \"vehiculos_pib.csv\"\n",
    "\n",
    "# =========================\n",
    "# 2) Utilidades\n",
    "# =========================\n",
    "def read_csv_robust(path: Path) -> pd.DataFrame:\n",
    "    if not Path(path).exists():\n",
    "        raise FileNotFoundError(f\"No se encontr√≥ el archivo: {path}\")\n",
    "    for enc in (\"utf-8\", \"latin1\", \"cp1252\"):\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out.columns = (\n",
    "        out.columns.str.strip().str.lower()\n",
    "        .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "        .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
    "    )\n",
    "    return out\n",
    "\n",
    "def strip_accents_series(s: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        s.astype(str)\n",
    "         .str.normalize(\"NFKD\")\n",
    "         .str.encode(\"ascii\", errors=\"ignore\")\n",
    "         .str.decode(\"utf-8\")\n",
    "    )\n",
    "\n",
    "def norm_dep(series: pd.Series) -> pd.Series:\n",
    "    s = strip_accents_series(series.fillna(\"\").astype(str).str.lower().str.strip())\n",
    "    repl = {\n",
    "        \"bogota dc\": \"bogota\",\n",
    "        \"bogota, d.c.\": \"bogota\",\n",
    "        \"bogota d.c.\": \"bogota\",\n",
    "        \"archipielago de san andres, providencia y santa catalina\": \"san andres y providencia\",\n",
    "        \"san andres\": \"san andres y providencia\",\n",
    "    }\n",
    "    return s.replace(repl)\n",
    "\n",
    "def coerce_year(series: pd.Series) -> pd.Series:\n",
    "    y = series.astype(str).str.extract(r\"(\\d{4})\", expand=False)\n",
    "    return pd.to_numeric(y, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "def fix_code_str(s: pd.Series) -> pd.Series:\n",
    "    code = s.astype(str).str.extract(r\"(\\d+)\", expand=False)\n",
    "    return code.where(code.isna(), code.str.zfill(2))\n",
    "\n",
    "def first_present(df: pd.DataFrame, names) -> str | None:\n",
    "    for n in names:\n",
    "        if n in df.columns:\n",
    "            return n\n",
    "    return None\n",
    "\n",
    "# =========================\n",
    "# 3) Veh√≠culos: EV y HEV por anio-departamento\n",
    "# =========================\n",
    "veh = normalize_cols(read_csv_robust(VEH_PATH))\n",
    "\n",
    "dep_col  = first_present(veh, [\"departamento\",\"departamento_nombre\",\"depto\",\"dpto\"])\n",
    "anio_col = first_present(veh, [\"anio\",\"ano\",\"a√±o\",\"anio_registro\",\"anioinscripcion\",\"anio_modelo\",\"year\",\"periodo\"])\n",
    "fecha_col = first_present(veh, [\"fecha_registro\",\"fecha\",\"fec_registro\"])\n",
    "cod_col  = first_present(veh, [\"codigo_departamento\",\"codigo_depto\",\"cod_departamento\",\"cod_depto\",\"cod_dane\",\"codigo_dane\"])\n",
    "tipo_col = first_present(veh, [\"tipo_vehiculo\",\"tipo\",\"categoria\"])\n",
    "\n",
    "if not (dep_col and tipo_col):\n",
    "    raise ValueError(f\"Veh√≠culos: faltan columnas clave (departamento/tipo). Columnas: {veh.columns.tolist()}\")\n",
    "\n",
    "veh[\"_departamento_\"] = norm_dep(veh[dep_col])\n",
    "veh[\"_cod_depto_\"] = fix_code_str(veh[cod_col]) if cod_col else pd.NA\n",
    "\n",
    "# A√±o: usar columna de a√±o si existe; si no, extraer de la fecha\n",
    "if anio_col:\n",
    "    veh[\"_anio_\"] = coerce_year(veh[anio_col])\n",
    "elif fecha_col:\n",
    "    veh[\"_anio_\"] = coerce_year(veh[fecha_col])\n",
    "else:\n",
    "    raise ValueError(\"Veh√≠culos: no se encontr√≥ columna de a√±o ni fecha para derivarlo.\")\n",
    "\n",
    "# Conteo: si hay columna de cantidad, √∫sala; si no, cuenta filas\n",
    "cant_col = first_present(veh, [\"cantidad\",\"n\",\"count\",\"conteo\",\"valor\"])\n",
    "veh[\"_cnt_\"] = pd.to_numeric(veh[cant_col], errors=\"coerce\").fillna(0) if cant_col else 1\n",
    "\n",
    "# Normalizar tipo (EV / HEV)\n",
    "tipo_norm = veh[tipo_col].astype(str).str.upper().str.strip()\n",
    "veh[\"_tipo_\"] = np.select(\n",
    "    [\n",
    "        tipo_norm.str.contains(r\"\\bEV\\b\") & ~tipo_norm.str.contains(\"HEV|PHEV\"),\n",
    "        tipo_norm.str.contains(r\"\\bHEV\\b\"),\n",
    "    ],\n",
    "    [\"EV\",\"HEV\"],\n",
    "    default=\"OTRO\"\n",
    ")\n",
    "\n",
    "veh_grp = (\n",
    "    veh.groupby([\"_anio_\",\"_cod_depto_\",\"_departamento_\",\"_tipo_\"], dropna=False)[\"_cnt_\"]\n",
    "       .sum()\n",
    "       .reset_index()\n",
    ")\n",
    "\n",
    "veh_piv = veh_grp.pivot_table(\n",
    "    index=[\"_anio_\",\"_cod_depto_\",\"_departamento_\"],\n",
    "    columns=\"_tipo_\",\n",
    "    values=\"_cnt_\",\n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "veh_piv.columns.name = None\n",
    "\n",
    "veh_piv[\"ev_registrados\"]  = veh_piv.get(\"EV\", 0)\n",
    "veh_piv[\"hev_registrados\"] = veh_piv.get(\"HEV\", 0)\n",
    "veh_min = veh_piv[[\"_anio_\",\"_cod_depto_\",\"_departamento_\",\"ev_registrados\",\"hev_registrados\"]].copy()\n",
    "\n",
    "# =========================\n",
    "# 4) PIB\n",
    "# =========================\n",
    "pib = normalize_cols(read_csv_robust(PIB_PATH))\n",
    "\n",
    "dep_pib = first_present(pib, [\"departamento\",\"departamento_nombre\",\"depto\",\"dpto\"])\n",
    "anio_pib = first_present(pib, [\"anio\",\"ano\",\"a√±o\",\"anio_registro\",\"year\",\"periodo\"])\n",
    "cod_pib  = first_present(pib, [\"codigo_departamento\",\"codigo_depto\",\"cod_departamento\",\"cod_depto\",\"cod_dane\",\"codigo_dane\"])\n",
    "pib_col  = next((c for c in pib.columns if \"pib\" in c), None)\n",
    "\n",
    "if not (dep_pib and (anio_pib or fecha_col) and pib_col):\n",
    "    raise ValueError(f\"PIB: faltan columnas (departamento/anio/pib). Columnas: {pib.columns.tolist()}\")\n",
    "\n",
    "pib[\"_departamento_\"] = norm_dep(pib[dep_pib])\n",
    "pib[\"_anio_\"] = coerce_year(pib[anio_pib]) if anio_pib else pd.NA\n",
    "pib[\"_cod_depto_\"] = fix_code_str(pib[cod_pib]) if cod_pib else pd.NA\n",
    "pib[\"pib_const_2015\"] = pd.to_numeric(pib[pib_col], errors=\"coerce\")\n",
    "\n",
    "pib_min = pib[[\"_anio_\",\"_cod_depto_\",\"_departamento_\",\"pib_const_2015\"]].copy()\n",
    "\n",
    "# =========================\n",
    "# 5) MERGE y columnas finales\n",
    "# =========================\n",
    "df = veh_min.merge(pib_min, on=[\"_anio_\",\"_cod_depto_\",\"_departamento_\"], how=\"left\")\n",
    "\n",
    "# Si qued√≥ PIB nulo, intentar completar por (anio + nombre)\n",
    "mask = df[\"pib_const_2015\"].isna()\n",
    "if mask.any():\n",
    "    alt = pib_min.drop(columns=[\"_cod_depto_\"]).drop_duplicates([\"_anio_\",\"_departamento_\"])\n",
    "    df.loc[mask, \"pib_const_2015\"] = df[mask].merge(\n",
    "        alt, on=[\"_anio_\",\"_departamento_\"], how=\"left\"\n",
    "    )[\"pib_const_2015_y\"].values\n",
    "\n",
    "df[\"anio\"] = df[\"_anio_\"]\n",
    "df[\"codigo_departamento\"] = df[\"_cod_depto_\"].replace({\"<NA>\": np.nan})\n",
    "df[\"departamento\"] = df[\"_departamento_\"].str.upper()\n",
    "\n",
    "dataset = df[[\n",
    "    \"anio\",\"codigo_departamento\",\"departamento\",\n",
    "    \"ev_registrados\",\"hev_registrados\",\"pib_const_2015\"\n",
    "]].sort_values([\"departamento\",\"anio\"]).reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# 6) Guardado + chequeos\n",
    "# =========================\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "dataset.to_csv(OUT_PATH, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\">>> Guardado:\", OUT_PATH)\n",
    "print(\"Shape:\", dataset.shape)\n",
    "print(\"Columnas:\", list(dataset.columns))\n",
    "print(\"NaNs por columna:\\n\", dataset.isna().sum())\n",
    "if {\"departamento\",\"anio\"}.issubset(dataset.columns):\n",
    "    print(\"Duplicados (departamento, anio):\", dataset.duplicated(subset=[\"departamento\",\"anio\"]).sum())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
